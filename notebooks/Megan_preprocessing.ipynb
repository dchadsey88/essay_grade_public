{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim.models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# from sklearn.naive_bayes import BernoulliNB\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.tree import ExtraTreeClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.neighbors import NearestCentroid\n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import RidgeClassifier\n",
    "# from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, Dense, Flatten, MaxPool1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>level</th>\n",
       "      <th>title_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The question is asking that, in the same disci...</td>\n",
       "      <td>2017</td>\n",
       "      <td>4, 5 - Est_Chen-fzn235-TOK_essay.docx</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Given access to the same facts, how is it poss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our brains seek coherence, structure, and orde...</td>\n",
       "      <td>2017</td>\n",
       "      <td>7, 6 - Eva GuoTOK_final_final_draft.docx</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Humans are pattern-seeking animals and we are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In American Heritage® Dictionary of the Englis...</td>\n",
       "      <td>2017</td>\n",
       "      <td>7, 5 - fzn260_Yessica_Ji_Yuanyi_G12-9_TOKEssay...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Given access to the same facts, how is it poss...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  year  \\\n",
       "0  The question is asking that, in the same disci...  2017   \n",
       "1  Our brains seek coherence, structure, and orde...  2017   \n",
       "2  In American Heritage® Dictionary of the Englis...  2017   \n",
       "\n",
       "                                                name  title  score  level  \\\n",
       "0              4, 5 - Est_Chen-fzn235-TOK_essay.docx      5      4      2   \n",
       "1           7, 6 - Eva GuoTOK_final_final_draft.docx      6      7      4   \n",
       "2  7, 5 - fzn260_Yessica_Ji_Yuanyi_G12-9_TOKEssay...      5      7      4   \n",
       "\n",
       "                                          title_name  \n",
       "0  Given access to the same facts, how is it poss...  \n",
       "1  Humans are pattern-seeking animals and we are ...  \n",
       "2  Given access to the same facts, how is it poss...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df =  pd.read_csv(r'../essay_grader/data/essay_data.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = clean_string(test_data,'text',period = True, replacement = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_string(df,column,period = False, replacement = ''):\n",
    "    \n",
    "    df_new = df.copy()   \n",
    "    new_list = []\n",
    "    \n",
    "    # Covert all words to lower case\n",
    "    df_new[column] = df_new[column].str.lower()\n",
    "    # handle digits\n",
    "    df_new[column] = df_new[column].str.replace('\\d+', replacement)\n",
    "    # Handle contractions\n",
    "    df_new[column] = df_new[column].str.replace(\"he's\", \"he is\")\n",
    "    df_new[column] = df_new[column].str.replace(\"we're\", \"we are\")\n",
    "    df_new[column] = df_new[column].str.replace(\"they're\", \"they are\")\n",
    "    df_new[column] = df_new[column].str.replace(\"i'm\", \"i am\")\n",
    "    df_new[column] = df_new[column].str.replace(\"she's\", \"she is\")\n",
    "    df_new[column] = df_new[column].str.replace(\"it's\", \"it is\")\n",
    "    # Handle English punctuations except period\n",
    "    df_new[column] = df_new[column].str.replace('[-!#$%&\\'()*+,/:;<=>?@[\\\\]^_`{|}~\\t]',replacement)\n",
    "    df_new[column] = df_new[column].str.replace('\\\\',replacement)\n",
    "    # Handle period\n",
    "    if period:\n",
    "        df_new[column] = df_new[column].str.replace('.',replacement)\n",
    "    # Handle Chinese punctuations and Chinese characters\n",
    "    df_new[column] = df_new[column].str.replace(r'[^\\x00-\\x7F]+', replacement)\n",
    "    \n",
    "    #hanldle multiple line into one line for paragraph separator\n",
    "    for i in df_new.index:  \n",
    "        new_list.append(re.sub(r'\\n+','\\n', df_new[column][i]))   \n",
    "    df_new[column] = pd.DataFrame(new_list)\n",
    "    df_new[column][0]\n",
    "        \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove stopwords\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def remove_stopwords(x):\n",
    "    word_tokens = word_tokenize(x) \n",
    "    return ' '.join([w for w in word_tokens if not w in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_all(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove bibliography, works cited, word cited paragraph\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def remove_last_para(df,word):\n",
    "\n",
    "    list_test = []\n",
    "    df['text']= df.text.str.lower()\n",
    "\n",
    "    bool_list= df.text.str.contains(word, case = False, na = False)\n",
    "\n",
    "    for i in bool_list.index:\n",
    "\n",
    "        if bool_list[i] == False:\n",
    "            list_test.append(df['text'][i])\n",
    "\n",
    "        else:\n",
    "            l = df['text'][i].split(word)[0:-1]\n",
    "            l2 = word.join(l)\n",
    "            list_test.append(l2)\n",
    "\n",
    "    df['text'] = pd.DataFrame(list_test)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_all(df):\n",
    "    word_list = ['word cited','bibliography','works cited']\n",
    "    for i in word_list:\n",
    "        df = remove_last_para(df,i)       \n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_list= df.text.str.contains('word cited', case = False, na = False)\n",
    "bool_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "\n",
    "for i in bool_list.index:\n",
    "    if bool_list[i] == True:\n",
    "        test_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# one sentencse only for test \n",
    "test_list = []\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(df)\n",
    "\n",
    "for token in doc:\n",
    "    test_list.append(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-9eedd5cd1eb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msentes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_new' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "p = df_new['text'][0]\n",
    "\n",
    "sentes = tokenize.sent_tokenize(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8777a5de27c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_new' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "import spacy\n",
    "import statistics\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "sentences = tokenize.sent_tokenize(df_new['text'][0])\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.96808510638298,\n",
       " 8.41891891891892,\n",
       " 10.071428571428571,\n",
       " 8.95774647887324,\n",
       " 9.157142857142857,\n",
       " 9.363636363636363,\n",
       " 8.321428571428571,\n",
       " 9.283783783783784,\n",
       " 9.642857142857142,\n",
       " 9.5625,\n",
       " 7.428571428571429,\n",
       " 8.654761904761905,\n",
       " 8.8,\n",
       " 9.41095890410959,\n",
       " 8.12087912087912,\n",
       " 8.988372093023257,\n",
       " 9.057971014492754,\n",
       " 8.010204081632653,\n",
       " 9.384615384615385,\n",
       " 9.175,\n",
       " 9.178082191780822,\n",
       " 8.1,\n",
       " 8.346153846153847,\n",
       " 8.08433734939759,\n",
       " 7.931034482758621,\n",
       " 7.761467889908257,\n",
       " 10.40983606557377,\n",
       " 7.584269662921348,\n",
       " 8.701149425287356,\n",
       " 8.541284403669724,\n",
       " 8.085365853658537,\n",
       " 9.05952380952381,\n",
       " 6.9035087719298245,\n",
       " 9.582089552238806,\n",
       " 7.932584269662922,\n",
       " 6.818181818181818,\n",
       " 7.394736842105263,\n",
       " 7.951219512195122,\n",
       " 9.507692307692308,\n",
       " 8.782608695652174,\n",
       " 9.173333333333334,\n",
       " 10.246153846153845,\n",
       " 8.717647058823529,\n",
       " 7.915094339622642,\n",
       " 8.144578313253012,\n",
       " 7.267441860465116,\n",
       " 7.786666666666667,\n",
       " 9.944444444444445,\n",
       " 8.946666666666667,\n",
       " 8.346534653465346,\n",
       " 8.417582417582418,\n",
       " 9.158730158730158,\n",
       " 8.423076923076923,\n",
       " 6.695652173913044,\n",
       " 8.76842105263158,\n",
       " 7.877551020408164,\n",
       " 7.92,\n",
       " 7.223529411764706,\n",
       " 9.055555555555555,\n",
       " 8.391304347826088,\n",
       " 9.705882352941176,\n",
       " 8.63,\n",
       " 9.567164179104477,\n",
       " 9.27536231884058,\n",
       " 9.0375,\n",
       " 8.948051948051948,\n",
       " 7.268817204301075,\n",
       " 7.445378151260504,\n",
       " 7.758241758241758,\n",
       " 9.828125,\n",
       " 8.48235294117647,\n",
       " 8.099009900990099,\n",
       " 7.076086956521739,\n",
       " 9.118421052631579,\n",
       " 9.743589743589743,\n",
       " 6.7032967032967035,\n",
       " 9.149253731343284,\n",
       " 8.61038961038961,\n",
       " 8.681818181818182,\n",
       " 8.266666666666667,\n",
       " 9.457627118644067,\n",
       " 7.970873786407767,\n",
       " 8.271844660194175,\n",
       " 8.419753086419753,\n",
       " 9.983333333333333,\n",
       " 7.135135135135135,\n",
       " 7.7272727272727275,\n",
       " 8.68918918918919,\n",
       " 8.902439024390244,\n",
       " 6.603305785123967,\n",
       " 8.839506172839506,\n",
       " 7.716216216216216,\n",
       " 9.461538461538462,\n",
       " 8.94186046511628,\n",
       " 10.5,\n",
       " 8.774193548387096,\n",
       " 9.757575757575758,\n",
       " 9.40983606557377,\n",
       " 8.21505376344086,\n",
       " 9.085714285714285,\n",
       " 9.253164556962025,\n",
       " 6.862903225806452,\n",
       " 7.601851851851852,\n",
       " 8.573529411764707,\n",
       " 9.060975609756097,\n",
       " 8.797101449275363,\n",
       " 8.758241758241759,\n",
       " 9.707692307692307,\n",
       " 9.038461538461538,\n",
       " 8.854545454545455,\n",
       " 7.081967213114754,\n",
       " 7.826086956521739,\n",
       " 8.325581395348838,\n",
       " 9.98360655737705,\n",
       " 7.563106796116505,\n",
       " 7.772151898734177,\n",
       " 8.942857142857143,\n",
       " 9.097560975609756,\n",
       " 8.61,\n",
       " 9.447368421052632,\n",
       " 8.705882352941176,\n",
       " 8.452380952380953,\n",
       " 8.802197802197803,\n",
       " 7.428571428571429,\n",
       " 8.361702127659575,\n",
       " 8.507042253521126,\n",
       " 8.753246753246753,\n",
       " 8.7625,\n",
       " 9.45945945945946,\n",
       " 10.017543859649123,\n",
       " 8.736263736263735,\n",
       " 9.454545454545455,\n",
       " 7.7555555555555555,\n",
       " 7.739583333333333,\n",
       " 8.443037974683545,\n",
       " 9.144927536231885,\n",
       " 8.311111111111112,\n",
       " 9.47887323943662,\n",
       " 7.775510204081633,\n",
       " 9.63768115942029,\n",
       " 8.865853658536585,\n",
       " 8.285714285714286,\n",
       " 8.22549019607843,\n",
       " 9.061728395061728,\n",
       " 9.6,\n",
       " 9.202898550724637,\n",
       " 9.333333333333334,\n",
       " 9.034883720930232,\n",
       " 8.565217391304348,\n",
       " 8.791208791208792,\n",
       " 9.596153846153847,\n",
       " 9.049382716049383,\n",
       " 8.54945054945055,\n",
       " 9.784615384615385,\n",
       " 8.17142857142857,\n",
       " 7.489130434782608,\n",
       " 8.5,\n",
       " 8.434782608695652,\n",
       " 8.80232558139535,\n",
       " 9.711864406779661,\n",
       " 8.698795180722891,\n",
       " 9.081967213114755,\n",
       " 9.132352941176471,\n",
       " 9.32857142857143,\n",
       " 8.987012987012987,\n",
       " 9,\n",
       " 8.857142857142858,\n",
       " 8.202380952380953,\n",
       " 9.530303030303031,\n",
       " 8.674418604651162,\n",
       " 10.152777777777779,\n",
       " 9.310344827586206,\n",
       " 8.118279569892474,\n",
       " 9.301369863013699,\n",
       " 8.571428571428571,\n",
       " 9.060240963855422,\n",
       " 9.32857142857143,\n",
       " 8.189473684210526,\n",
       " 8.666666666666666,\n",
       " 7.644444444444445,\n",
       " 9.81578947368421,\n",
       " 8.607142857142858,\n",
       " 9.215909090909092,\n",
       " 9.076923076923077,\n",
       " 8.467391304347826,\n",
       " 8.44186046511628,\n",
       " 9.238095238095237,\n",
       " 9.698412698412698,\n",
       " 9.442857142857143,\n",
       " 8.971830985915492,\n",
       " 9.682539682539682,\n",
       " 8.973684210526315,\n",
       " 8.123809523809523,\n",
       " 9.168831168831169,\n",
       " 9.12,\n",
       " 8.08421052631579,\n",
       " 8.263736263736265,\n",
       " 9.445945945945946,\n",
       " 9.044117647058824,\n",
       " 9.916666666666666,\n",
       " 9.41891891891892,\n",
       " 8.7,\n",
       " 8.615384615384615,\n",
       " 8.829545454545455,\n",
       " 7.9411764705882355,\n",
       " 9.870967741935484,\n",
       " 9.367647058823529,\n",
       " 9.253521126760564,\n",
       " 8.975903614457831,\n",
       " 9.072289156626505,\n",
       " 8.520547945205479,\n",
       " 9.107692307692307,\n",
       " 9.158730158730158,\n",
       " 8.719101123595506,\n",
       " 8.814285714285715,\n",
       " 9.492063492063492,\n",
       " 8.767441860465116,\n",
       " 8.202247191011235,\n",
       " 9.228571428571428,\n",
       " 9.507936507936508,\n",
       " 8.84,\n",
       " 9.425925925925926,\n",
       " 8.396039603960396,\n",
       " 9.233766233766234,\n",
       " 10.017857142857142,\n",
       " 8.757142857142858,\n",
       " 9.516129032258064,\n",
       " 9.219178082191782,\n",
       " 8.902439024390244,\n",
       " 9.223684210526315,\n",
       " 8.938271604938272,\n",
       " 9,\n",
       " 9.5,\n",
       " 9.063291139240507,\n",
       " 9.516666666666667,\n",
       " 7.860215053763441,\n",
       " 10.351851851851851,\n",
       " 9.61038961038961,\n",
       " 9.898305084745763,\n",
       " 9.175675675675675,\n",
       " 8.556818181818182,\n",
       " 8.8125,\n",
       " 8.28888888888889,\n",
       " 9.67142857142857,\n",
       " 8.5,\n",
       " 9.292307692307693,\n",
       " 8.188888888888888,\n",
       " 8.730337078651685,\n",
       " 10.344827586206897,\n",
       " 8.146341463414634,\n",
       " 8.650602409638553,\n",
       " 9.03448275862069,\n",
       " 8.753623188405797,\n",
       " 8.222222222222221,\n",
       " 8.8125,\n",
       " 9.352941176470589,\n",
       " 8.985714285714286,\n",
       " 9.024691358024691,\n",
       " 9.779661016949152,\n",
       " 9.774193548387096,\n",
       " 9.394366197183098,\n",
       " 9.206896551724139,\n",
       " 9.180327868852459,\n",
       " 9.850746268656716,\n",
       " 8.229166666666666,\n",
       " 8.454545454545455,\n",
       " 8.736842105263158,\n",
       " 9.409638554216867,\n",
       " 8.506172839506172,\n",
       " 10.204081632653061,\n",
       " 9.4,\n",
       " 9.152941176470588,\n",
       " 9.4,\n",
       " 9,\n",
       " 9.08433734939759,\n",
       " 8.7875,\n",
       " 9.588235294117647,\n",
       " 8.9875,\n",
       " 8.577777777777778,\n",
       " 8.9,\n",
       " 8.847222222222221,\n",
       " 7.967391304347826,\n",
       " 8.095890410958905,\n",
       " 8.8375,\n",
       " 9,\n",
       " 8.863636363636363,\n",
       " 8.848101265822784,\n",
       " 9.028571428571428,\n",
       " 8.731707317073171,\n",
       " 9.467532467532468,\n",
       " 8.829545454545455,\n",
       " 7.760416666666667,\n",
       " 9.24,\n",
       " 8.368421052631579,\n",
       " 8.904761904761905,\n",
       " 8.61111111111111,\n",
       " 8.543859649122806,\n",
       " 8.6875,\n",
       " 9.793103448275861,\n",
       " 8.507246376811594,\n",
       " 10.354166666666666,\n",
       " 9.6875,\n",
       " 8.658536585365853,\n",
       " 9.382352941176471,\n",
       " 10.126984126984127,\n",
       " 8.21111111111111,\n",
       " 8.202380952380953,\n",
       " 8.746666666666666,\n",
       " 10.452380952380953,\n",
       " 9.098360655737705,\n",
       " 9.072463768115941,\n",
       " 8.927710843373495,\n",
       " 9.526881720430108,\n",
       " 8.692307692307692,\n",
       " 8.722222222222221,\n",
       " 7.9375,\n",
       " 9.076923076923077,\n",
       " 9.23728813559322,\n",
       " 7.755102040816326,\n",
       " 8.01980198019802,\n",
       " 8.96103896103896,\n",
       " 8.623188405797102,\n",
       " 9.26027397260274,\n",
       " 8.984126984126984,\n",
       " 8.561643835616438,\n",
       " 9.732142857142858,\n",
       " 8.935897435897436,\n",
       " 8.645569620253164,\n",
       " 8.974025974025974,\n",
       " 9.666666666666666,\n",
       " 8.9,\n",
       " 9.385964912280702,\n",
       " 9.202702702702704,\n",
       " 8.64935064935065,\n",
       " 8.471264367816092,\n",
       " 8.604651162790697,\n",
       " 8.325301204819278,\n",
       " 10.723076923076922,\n",
       " 7.950980392156863,\n",
       " 9.244186046511627,\n",
       " 10.044444444444444,\n",
       " 10.272727272727273,\n",
       " 9.597222222222221,\n",
       " 9.275,\n",
       " 8.661538461538461,\n",
       " 9.240506329113924,\n",
       " 7.78125,\n",
       " 9.146666666666667,\n",
       " 9.590909090909092,\n",
       " 8.845070422535212,\n",
       " 9.256410256410257,\n",
       " 9.232876712328768,\n",
       " 9.246376811594203,\n",
       " 8.379310344827585,\n",
       " 8.943661971830986,\n",
       " 8.780821917808218,\n",
       " 8.855263157894736,\n",
       " 10.115384615384615,\n",
       " 8.661290322580646,\n",
       " 8.23469387755102,\n",
       " 8.94047619047619,\n",
       " 9.147058823529411,\n",
       " 8.80952380952381,\n",
       " 7.533980582524272,\n",
       " 9.194444444444445,\n",
       " 9.81081081081081,\n",
       " 8.72972972972973,\n",
       " 9.4,\n",
       " 10.767441860465116,\n",
       " 9.65625,\n",
       " 9.660714285714286,\n",
       " 8.878378378378379,\n",
       " 7.88659793814433,\n",
       " 9.10958904109589,\n",
       " 9.414285714285715,\n",
       " 9.666666666666666,\n",
       " 8.522727272727273,\n",
       " 7.659574468085107,\n",
       " 8.670731707317072,\n",
       " 8.640776699029127,\n",
       " 8.448275862068966,\n",
       " 9.681818181818182,\n",
       " 8.623376623376624,\n",
       " 8.644736842105264,\n",
       " 8.67123287671233,\n",
       " 8.625,\n",
       " 9.615384615384615,\n",
       " 10,\n",
       " 8.483516483516484,\n",
       " 8.592105263157896,\n",
       " 9.380281690140846,\n",
       " 9.508196721311476,\n",
       " 7.866666666666666,\n",
       " 9.725806451612904,\n",
       " 9.432432432432432,\n",
       " 8.975903614457831,\n",
       " 9.7,\n",
       " 10.279069767441861,\n",
       " 9.043478260869565,\n",
       " 8.571428571428571,\n",
       " 7.921568627450981,\n",
       " 9.085365853658537,\n",
       " 8.144736842105264,\n",
       " 9.140845070422536,\n",
       " 8.402439024390244,\n",
       " 9.634615384615385,\n",
       " 8.75,\n",
       " 8.453488372093023,\n",
       " 9.04054054054054,\n",
       " 9.063291139240507,\n",
       " 8.979166666666666,\n",
       " 8.53763440860215,\n",
       " 8.163934426229508,\n",
       " 8.67816091954023,\n",
       " 8.340659340659341,\n",
       " 9.857142857142858,\n",
       " 8.708860759493671,\n",
       " 9.068493150684931,\n",
       " 8.275862068965518,\n",
       " 7.972222222222222,\n",
       " 9.421875,\n",
       " 8.74025974025974,\n",
       " 8.839080459770114,\n",
       " 8.141304347826088,\n",
       " 9.403225806451612,\n",
       " 8.71951219512195,\n",
       " 7.284403669724771,\n",
       " 9.2,\n",
       " 8.571428571428571,\n",
       " 8.675,\n",
       " 8.304347826086957,\n",
       " 7.986666666666666,\n",
       " 8.337209302325581,\n",
       " 9.022988505747126,\n",
       " 8.478260869565217,\n",
       " 7.927710843373494,\n",
       " 9.08108108108108,\n",
       " 9.547945205479452,\n",
       " 9.372881355932204,\n",
       " 8.935064935064934,\n",
       " 8.92,\n",
       " 9.04225352112676,\n",
       " 9.363636363636363,\n",
       " 8.78888888888889,\n",
       " 8.555555555555555,\n",
       " 9.619047619047619,\n",
       " 9.741379310344827,\n",
       " 10.127272727272727,\n",
       " 8.554054054054054,\n",
       " 9.36986301369863,\n",
       " 8.173913043478262,\n",
       " 9.024096385542169,\n",
       " 8.965909090909092,\n",
       " 8.255813953488373,\n",
       " 9.144927536231885,\n",
       " 9.012195121951219,\n",
       " 9.132352941176471,\n",
       " 8.466019417475728,\n",
       " 9.31578947368421,\n",
       " 8.174603174603174,\n",
       " 9.966101694915254,\n",
       " 8.553846153846154,\n",
       " 8.592592592592593,\n",
       " 9.206349206349206,\n",
       " 9.564516129032258,\n",
       " 8.916666666666666,\n",
       " 7.4950495049504955,\n",
       " 8.06060606060606,\n",
       " 8.645569620253164,\n",
       " 9.012048192771084,\n",
       " 9.23943661971831,\n",
       " 8.447058823529412,\n",
       " 9.651515151515152,\n",
       " 8.417910447761194,\n",
       " 9.202380952380953,\n",
       " 8.73913043478261,\n",
       " 9.75,\n",
       " 9.388059701492537,\n",
       " 9.144736842105264,\n",
       " 9.127272727272727,\n",
       " 9.029850746268657,\n",
       " 8.24,\n",
       " 9.558823529411764,\n",
       " 9.396825396825397,\n",
       " 9.342465753424657,\n",
       " 8.867647058823529,\n",
       " 9.506849315068493,\n",
       " 9.178082191780822,\n",
       " 9.041666666666666,\n",
       " 8.414141414141413,\n",
       " 10.392857142857142,\n",
       " 8.932432432432432,\n",
       " 8.539473684210526,\n",
       " 8.74390243902439,\n",
       " 8.170454545454545,\n",
       " 8.391752577319588,\n",
       " 8.25]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "import spacy\n",
    "import statistics\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "\n",
    "mean_unique_all_eassy = []\n",
    "\n",
    "for index in df_new.index:\n",
    "    sentences = tokenize.sent_tokenize(df_new['text'][index])\n",
    "    \n",
    "    len_unique_eassy =[]  \n",
    "    for i in range(len(sentences)):\n",
    "        doc = nlp(sentences[i])        \n",
    "        \n",
    "        word_type_list =[]\n",
    "        for token in doc:\n",
    "            word_type_list.append(token.pos_)   \n",
    "            \n",
    "        len_unique_eassy.append(len(set(word_type_list)))\n",
    "    \n",
    "    mean_unique_all_eassy.append(statistics.mean(len_unique_eassy))\n",
    "\n",
    "mean_unique_all_eassy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['mean_part_speech'] = pd.DataFrame(mean_unique_all_eassy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-536-94dbd581444b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_new' is not defined"
     ]
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.838400</td>\n",
       "      <td>0.682460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.899004</td>\n",
       "      <td>0.682339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.859543</td>\n",
       "      <td>0.719587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.742993</td>\n",
       "      <td>0.682382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.684439</td>\n",
       "      <td>0.645505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean       std\n",
       "level                    \n",
       "1      8.838400  0.682460\n",
       "2      8.899004  0.682339\n",
       "3      8.859543  0.719587\n",
       "4      8.742993  0.682382\n",
       "5      8.684439  0.645505"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.groupby('level').mean_part_speech.agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12,\n",
       " 9,\n",
       " 7,\n",
       " 13,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 11,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 9,\n",
       " 11,\n",
       " 10,\n",
       " 14,\n",
       " 10,\n",
       " 10,\n",
       " 14,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 12,\n",
       " 10,\n",
       " 9,\n",
       " 11,\n",
       " 7,\n",
       " 15,\n",
       " 10,\n",
       " 12,\n",
       " 8,\n",
       " 9,\n",
       " 13,\n",
       " 12,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 14,\n",
       " 9,\n",
       " 13,\n",
       " 8,\n",
       " 10,\n",
       " 11,\n",
       " 9,\n",
       " 10,\n",
       " 14,\n",
       " 14,\n",
       " 10,\n",
       " 14,\n",
       " 14,\n",
       " 9,\n",
       " 8,\n",
       " 13,\n",
       " 9,\n",
       " 13,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 11,\n",
       " 8,\n",
       " 11,\n",
       " 11,\n",
       " 10,\n",
       " 8,\n",
       " 8,\n",
       " 12,\n",
       " 12,\n",
       " 9,\n",
       " 10,\n",
       " 13,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 14,\n",
       " 8,\n",
       " 9,\n",
       " 13,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 11,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 14,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 14,\n",
       " 10,\n",
       " 9,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 14,\n",
       " 10,\n",
       " 10,\n",
       " 12,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 12,\n",
       " 11,\n",
       " 14,\n",
       " 9,\n",
       " 9,\n",
       " 11,\n",
       " 13,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 15,\n",
       " 10,\n",
       " 11,\n",
       " 14,\n",
       " 9,\n",
       " 9,\n",
       " 11,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 12,\n",
       " 9,\n",
       " 9,\n",
       " 11,\n",
       " 7,\n",
       " 9,\n",
       " 12,\n",
       " 8,\n",
       " 8,\n",
       " 14,\n",
       " 9,\n",
       " 11,\n",
       " 12,\n",
       " 9,\n",
       " 11,\n",
       " 10,\n",
       " 12,\n",
       " 11,\n",
       " 13,\n",
       " 9,\n",
       " 8,\n",
       " 15,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 12,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 11,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 12,\n",
       " 10,\n",
       " 11,\n",
       " 9,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 9,\n",
       " 10,\n",
       " 15,\n",
       " 10,\n",
       " 12,\n",
       " 8,\n",
       " 11,\n",
       " 11,\n",
       " 10,\n",
       " 10,\n",
       " 13,\n",
       " 10,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 10,\n",
       " 11,\n",
       " 10,\n",
       " 10,\n",
       " 8,\n",
       " 13,\n",
       " 13,\n",
       " 9,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 11,\n",
       " 10,\n",
       " 8,\n",
       " 12,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 14,\n",
       " 9,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 12,\n",
       " 7,\n",
       " 8,\n",
       " 12,\n",
       " 8,\n",
       " 11,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 14,\n",
       " 11,\n",
       " 13,\n",
       " 10,\n",
       " 14,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 14,\n",
       " 11,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 9,\n",
       " 13,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 12,\n",
       " 13,\n",
       " 12,\n",
       " 12,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 7,\n",
       " 10,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 13,\n",
       " 11,\n",
       " 12,\n",
       " 9,\n",
       " 9,\n",
       " 11,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 8,\n",
       " 13,\n",
       " 14,\n",
       " 11,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 10,\n",
       " 13,\n",
       " 9,\n",
       " 8,\n",
       " 11,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 14,\n",
       " 11,\n",
       " 13,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 13,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 11,\n",
       " 9,\n",
       " 11,\n",
       " 8,\n",
       " 9,\n",
       " 12,\n",
       " 10,\n",
       " 10,\n",
       " 12,\n",
       " 11,\n",
       " 10,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 13,\n",
       " 10,\n",
       " 13,\n",
       " 11,\n",
       " 14,\n",
       " 9,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 13,\n",
       " 14,\n",
       " 12,\n",
       " 9,\n",
       " 13,\n",
       " 11,\n",
       " 11,\n",
       " 9,\n",
       " 13,\n",
       " 10,\n",
       " 12,\n",
       " 12,\n",
       " 10,\n",
       " 14,\n",
       " 11,\n",
       " 13,\n",
       " 13,\n",
       " 9,\n",
       " 9,\n",
       " 12,\n",
       " 12,\n",
       " 10,\n",
       " 10,\n",
       " 14,\n",
       " 11,\n",
       " 11,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 11,\n",
       " 8,\n",
       " 10,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 9,\n",
       " 11,\n",
       " 8,\n",
       " 9,\n",
       " 12,\n",
       " 10,\n",
       " 13,\n",
       " 10,\n",
       " 10,\n",
       " 15,\n",
       " 12,\n",
       " 9,\n",
       " 12,\n",
       " 9,\n",
       " 11,\n",
       " 12,\n",
       " 9,\n",
       " 14,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 14,\n",
       " 8,\n",
       " 11,\n",
       " 10,\n",
       " 13,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 14,\n",
       " 9,\n",
       " 10,\n",
       " 14,\n",
       " 9,\n",
       " 10,\n",
       " 9,\n",
       " 12,\n",
       " 9,\n",
       " 15,\n",
       " 11,\n",
       " 10,\n",
       " 13]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "import spacy\n",
    "import statistics\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "mean_unique_all_eassy = []\n",
    "\n",
    "for index in df_new.index:\n",
    "    sentences = tokenize.sent_tokenize(df_new['text'][index])\n",
    "    \n",
    "    len_unique_eassy =[]  \n",
    "    for i in range(len(sentences)):\n",
    "        doc = nlp(sentences[i])        \n",
    "        \n",
    "        word_type_list =[]\n",
    "        for token in doc:\n",
    "            word_type_list.append(token.pos_)   \n",
    "            \n",
    "        len_unique_eassy.append(len(set(word_type_list)))\n",
    "    \n",
    "    mean_unique_all_eassy.append(len(set(len_unique_eassy)))\n",
    "\n",
    "mean_unique_all_eassy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.653061</td>\n",
       "      <td>1.640008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.400000</td>\n",
       "      <td>1.763144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.314465</td>\n",
       "      <td>1.790051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.406250</td>\n",
       "      <td>1.900031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.800000</td>\n",
       "      <td>0.836660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       std\n",
       "level                     \n",
       "1      10.653061  1.640008\n",
       "2      10.400000  1.763144\n",
       "3      10.314465  1.790051\n",
       "4      10.406250  1.900031\n",
       "5       9.800000  0.836660"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['variety_part_speech'] = pd.DataFrame(mean_unique_all_eassy)\n",
    "df_new.groupby('level').variety_part_speech.agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[96,\n",
       " 55,\n",
       " 38,\n",
       " 71,\n",
       " 66,\n",
       " 65,\n",
       " 62,\n",
       " 72,\n",
       " 54,\n",
       " 73,\n",
       " 83,\n",
       " 70,\n",
       " 56,\n",
       " 74,\n",
       " 92,\n",
       " 80,\n",
       " 65,\n",
       " 100,\n",
       " 63,\n",
       " 71,\n",
       " 73,\n",
       " 64,\n",
       " 101,\n",
       " 59,\n",
       " 41,\n",
       " 89,\n",
       " 58,\n",
       " 58,\n",
       " 74,\n",
       " 102,\n",
       " 65,\n",
       " 81,\n",
       " 72,\n",
       " 66,\n",
       " 88,\n",
       " 51,\n",
       " 98,\n",
       " 56,\n",
       " 64,\n",
       " 72,\n",
       " 75,\n",
       " 63,\n",
       " 85,\n",
       " 79,\n",
       " 86,\n",
       " 51,\n",
       " 75,\n",
       " 54,\n",
       " 73,\n",
       " 85,\n",
       " 93,\n",
       " 59,\n",
       " 83,\n",
       " 138,\n",
       " 90,\n",
       " 95,\n",
       " 79,\n",
       " 56,\n",
       " 56,\n",
       " 71,\n",
       " 66,\n",
       " 89,\n",
       " 67,\n",
       " 65,\n",
       " 75,\n",
       " 77,\n",
       " 67,\n",
       " 83,\n",
       " 64,\n",
       " 61,\n",
       " 91,\n",
       " 89,\n",
       " 58,\n",
       " 65,\n",
       " 77,\n",
       " 57,\n",
       " 57,\n",
       " 73,\n",
       " 88,\n",
       " 71,\n",
       " 59,\n",
       " 76,\n",
       " 71,\n",
       " 71,\n",
       " 59,\n",
       " 72,\n",
       " 89,\n",
       " 70,\n",
       " 82,\n",
       " 102,\n",
       " 72,\n",
       " 52,\n",
       " 65,\n",
       " 74,\n",
       " 56,\n",
       " 94,\n",
       " 70,\n",
       " 60,\n",
       " 70,\n",
       " 70,\n",
       " 71,\n",
       " 78,\n",
       " 73,\n",
       " 53,\n",
       " 84,\n",
       " 54,\n",
       " 84,\n",
       " 63,\n",
       " 69,\n",
       " 42,\n",
       " 95,\n",
       " 73,\n",
       " 70,\n",
       " 61,\n",
       " 82,\n",
       " 83,\n",
       " 69,\n",
       " 81,\n",
       " 87,\n",
       " 63,\n",
       " 32,\n",
       " 74,\n",
       " 99,\n",
       " 68,\n",
       " 93,\n",
       " 72,\n",
       " 66,\n",
       " 70,\n",
       " 68,\n",
       " 56,\n",
       " 68,\n",
       " 53,\n",
       " 55,\n",
       " 60,\n",
       " 85,\n",
       " 62,\n",
       " 59,\n",
       " 67,\n",
       " 98,\n",
       " 64,\n",
       " 74,\n",
       " 91,\n",
       " 100,\n",
       " 72,\n",
       " 64,\n",
       " 77,\n",
       " 56,\n",
       " 73,\n",
       " 71,\n",
       " 79,\n",
       " 53,\n",
       " 71,\n",
       " 93,\n",
       " 60,\n",
       " 101,\n",
       " 58,\n",
       " 76,\n",
       " 46,\n",
       " 85,\n",
       " 53,\n",
       " 61,\n",
       " 63,\n",
       " 61,\n",
       " 67,\n",
       " 73,\n",
       " 64,\n",
       " 98,\n",
       " 82,\n",
       " 68,\n",
       " 79,\n",
       " 77,\n",
       " 63,\n",
       " 75,\n",
       " 87,\n",
       " 71,\n",
       " 82,\n",
       " 66,\n",
       " 88,\n",
       " 70,\n",
       " 56,\n",
       " 72,\n",
       " 70,\n",
       " 90,\n",
       " 75,\n",
       " 79,\n",
       " 73,\n",
       " 64,\n",
       " 61,\n",
       " 64,\n",
       " 64,\n",
       " 66,\n",
       " 65,\n",
       " 93,\n",
       " 76,\n",
       " 75,\n",
       " 93,\n",
       " 79,\n",
       " 71,\n",
       " 55,\n",
       " 60,\n",
       " 72,\n",
       " 77,\n",
       " 91,\n",
       " 89,\n",
       " 61,\n",
       " 56,\n",
       " 56,\n",
       " 61,\n",
       " 85,\n",
       " 78,\n",
       " 74,\n",
       " 61,\n",
       " 63,\n",
       " 73,\n",
       " 58,\n",
       " 56,\n",
       " 85,\n",
       " 74,\n",
       " 69,\n",
       " 59,\n",
       " 72,\n",
       " 49,\n",
       " 73,\n",
       " 65,\n",
       " 55,\n",
       " 55,\n",
       " 52,\n",
       " 70,\n",
       " 80,\n",
       " 76,\n",
       " 79,\n",
       " 61,\n",
       " 61,\n",
       " 67,\n",
       " 57,\n",
       " 66,\n",
       " 54,\n",
       " 73,\n",
       " 52,\n",
       " 66,\n",
       " 92,\n",
       " 85,\n",
       " 89,\n",
       " 69,\n",
       " 70,\n",
       " 62,\n",
       " 90,\n",
       " 69,\n",
       " 57,\n",
       " 66,\n",
       " 74,\n",
       " 70,\n",
       " 71,\n",
       " 88,\n",
       " 73,\n",
       " 62,\n",
       " 58,\n",
       " 71,\n",
       " 57,\n",
       " 63,\n",
       " 61,\n",
       " 53,\n",
       " 60,\n",
       " 65,\n",
       " 81,\n",
       " 56,\n",
       " 69,\n",
       " 74,\n",
       " 80,\n",
       " 47,\n",
       " 78,\n",
       " 85,\n",
       " 55,\n",
       " 49,\n",
       " 83,\n",
       " 72,\n",
       " 65,\n",
       " 74,\n",
       " 76,\n",
       " 86,\n",
       " 75,\n",
       " 68,\n",
       " 55,\n",
       " 83,\n",
       " 73,\n",
       " 66,\n",
       " 64,\n",
       " 67,\n",
       " 82,\n",
       " 72,\n",
       " 79,\n",
       " 102,\n",
       " 68,\n",
       " 70,\n",
       " 74,\n",
       " 89,\n",
       " 44,\n",
       " 55,\n",
       " 49,\n",
       " 54,\n",
       " 48,\n",
       " 64,\n",
       " 80,\n",
       " 67,\n",
       " 59,\n",
       " 70,\n",
       " 73,\n",
       " 72,\n",
       " 42,\n",
       " 60,\n",
       " 66,\n",
       " 76,\n",
       " 97,\n",
       " 66,\n",
       " 64,\n",
       " 72,\n",
       " 78,\n",
       " 56,\n",
       " 73,\n",
       " 108,\n",
       " 77,\n",
       " 64,\n",
       " 62,\n",
       " 60,\n",
       " 62,\n",
       " 56,\n",
       " 65,\n",
       " 67,\n",
       " 76,\n",
       " 53,\n",
       " 76,\n",
       " 60,\n",
       " 72,\n",
       " 76,\n",
       " 78,\n",
       " 79,\n",
       " 87,\n",
       " 58,\n",
       " 83,\n",
       " 94,\n",
       " 41,\n",
       " 58,\n",
       " 71,\n",
       " 82,\n",
       " 58,\n",
       " 82,\n",
       " 74,\n",
       " 60,\n",
       " 62,\n",
       " 68,\n",
       " 76,\n",
       " 62,\n",
       " 61,\n",
       " 89,\n",
       " 75,\n",
       " 67,\n",
       " 58,\n",
       " 52,\n",
       " 53,\n",
       " 85,\n",
       " 83,\n",
       " 69,\n",
       " 72,\n",
       " 102,\n",
       " 61,\n",
       " 70,\n",
       " 70,\n",
       " 62,\n",
       " 38,\n",
       " 61,\n",
       " 54,\n",
       " 74,\n",
       " 81,\n",
       " 73,\n",
       " 68,\n",
       " 52,\n",
       " 73,\n",
       " 98,\n",
       " 63,\n",
       " 76,\n",
       " 84,\n",
       " 64,\n",
       " 71,\n",
       " 68,\n",
       " 73,\n",
       " 78,\n",
       " 59,\n",
       " 55,\n",
       " 76,\n",
       " 59,\n",
       " 56,\n",
       " 61,\n",
       " 86,\n",
       " 61,\n",
       " 80,\n",
       " 76,\n",
       " 56,\n",
       " 35,\n",
       " 54,\n",
       " 64,\n",
       " 103,\n",
       " 78,\n",
       " 76,\n",
       " 66,\n",
       " 88,\n",
       " 48,\n",
       " 82,\n",
       " 82,\n",
       " 76,\n",
       " 77,\n",
       " 98,\n",
       " 90,\n",
       " 43,\n",
       " 80,\n",
       " 84,\n",
       " 57,\n",
       " 68,\n",
       " 66,\n",
       " 76,\n",
       " 104,\n",
       " 57,\n",
       " 73,\n",
       " 93,\n",
       " 85,\n",
       " 60,\n",
       " 79,\n",
       " 65,\n",
       " 59,\n",
       " 71,\n",
       " 78,\n",
       " 46,\n",
       " 57,\n",
       " 87,\n",
       " 81,\n",
       " 80,\n",
       " 69,\n",
       " 63,\n",
       " 72,\n",
       " 56,\n",
       " 60,\n",
       " 67,\n",
       " 61,\n",
       " 63,\n",
       " 86,\n",
       " 63,\n",
       " 67,\n",
       " 56,\n",
       " 53,\n",
       " 72,\n",
       " 64,\n",
       " 98,\n",
       " 78,\n",
       " 82,\n",
       " 79,\n",
       " 67,\n",
       " 67,\n",
       " 70,\n",
       " 79,\n",
       " 75,\n",
       " 59,\n",
       " 56,\n",
       " 73,\n",
       " 63,\n",
       " 58,\n",
       " 52,\n",
       " 81,\n",
       " 101,\n",
       " 66,\n",
       " 70,\n",
       " 85,\n",
       " 74,\n",
       " 84,\n",
       " 58,\n",
       " 59,\n",
       " 81,\n",
       " 67,\n",
       " 61,\n",
       " 63,\n",
       " 76,\n",
       " 46,\n",
       " 59,\n",
       " 59,\n",
       " 64,\n",
       " 55,\n",
       " 76,\n",
       " 63,\n",
       " 64,\n",
       " 74,\n",
       " 62,\n",
       " 88,\n",
       " 56,\n",
       " 75,\n",
       " 54,\n",
       " 80,\n",
       " 66,\n",
       " 85,\n",
       " 85]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "import spacy\n",
    "import statistics\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "vari_unique_all_eassy = []\n",
    "\n",
    "for index in df_new.index:\n",
    "    sentences = tokenize.sent_tokenize(df_new['text'][index])\n",
    "    \n",
    "    len_unique_eassy =[]  \n",
    "    for i in range(len(sentences)):\n",
    "        doc = nlp(sentences[i])        \n",
    "        \n",
    "        word_type_list =[]\n",
    "        for token in doc:\n",
    "            word_type_list.append(token.pos_)   \n",
    "            \n",
    "        len_unique_eassy.append(len(word_type_list))\n",
    "    \n",
    "    vari_unique_all_eassy.append(len(len_unique_eassy))\n",
    "\n",
    "vari_unique_all_eassy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73.448980</td>\n",
       "      <td>16.359326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.854545</td>\n",
       "      <td>13.003221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69.301887</td>\n",
       "      <td>12.551542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.390625</td>\n",
       "      <td>14.013165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>59.800000</td>\n",
       "      <td>14.855975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean        std\n",
       "level                      \n",
       "1      73.448980  16.359326\n",
       "2      70.854545  13.003221\n",
       "3      69.301887  12.551542\n",
       "4      70.390625  14.013165\n",
       "5      59.800000  14.855975"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['vari_unique_all_eassy'] = pd.DataFrame(vari_unique_all_eassy)\n",
    "df_new.groupby('level').vari_unique_all_eassy.agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adj</th>\n",
       "      <th>adp</th>\n",
       "      <th>adv</th>\n",
       "      <th>aux</th>\n",
       "      <th>cconj</th>\n",
       "      <th>det</th>\n",
       "      <th>intj</th>\n",
       "      <th>noun</th>\n",
       "      <th>num</th>\n",
       "      <th>part</th>\n",
       "      <th>pron</th>\n",
       "      <th>propn</th>\n",
       "      <th>punct</th>\n",
       "      <th>sconj</th>\n",
       "      <th>space</th>\n",
       "      <th>verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126</td>\n",
       "      <td>190</td>\n",
       "      <td>67</td>\n",
       "      <td>106</td>\n",
       "      <td>48</td>\n",
       "      <td>211</td>\n",
       "      <td>2</td>\n",
       "      <td>395</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>75</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>189</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adj  adp  adv  aux  cconj  det  intj  noun  num  part  pron  propn  punct  \\\n",
       "0  126  190   67  106     48  211     2   395    9    41    75     23      8   \n",
       "\n",
       "   sconj  space  verb  \n",
       "0     41    189   206  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = nlp(df_new['text'][0])\n",
    "\n",
    "word_type_list_essay = []\n",
    "for token in doc1:\n",
    "    word_type_list_essay.append(token.pos_)\n",
    "word_type_list_essay\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(word_type_list_essay)\n",
    "df_test_1= pd.DataFrame(X.toarray(),columns = vectorizer.get_feature_names())\n",
    "df_test2 = df_test_1.sum(axis=0)\n",
    "df_test3 = pd.DataFrame(df_test2).transpose()\n",
    "df_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'pos_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-890188b96a54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mword_type_list_essay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_level1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mword_type_list_essay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'pos_'"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "all_essay_word_list = []\n",
    "for index in df_level1.index:  \n",
    "        doc1 = nlp(df_new['text'][index])\n",
    "        \n",
    "        one_essay_word_type = []\n",
    "        for token in doc1:\n",
    "            word_type_list_essay.append(token.pos_)\n",
    "            vectorizer = CountVectorizer()\n",
    "            X = vectorizer.fit_transform(word_type_list_essay)\n",
    "            df_test_1= pd.DataFrame(X.toarray(),columns = vectorizer.get_feature_names())\n",
    "            df_test2 = df_test_1.sum(axis=0)\n",
    "            df_test3 = pd.DataFrame(df_test2).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a estimator for all levels \n",
    "# Take the estimator out the result for each articles \n",
    "piano_text = 'Gus who is learning piano is worried'\n",
    "piano_doc = nlp(piano_text)\n",
    "\n",
    "list_tst = []\n",
    "\n",
    "for token in piano_doc:\n",
    "    list_tst.append(token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'acomp'"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.dep_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16.90625,\n",
       " 30.636363636363637,\n",
       " 34.026315789473685,\n",
       " 25.35211267605634,\n",
       " 23.666666666666668,\n",
       " 25.16923076923077,\n",
       " 26.112903225806452,\n",
       " 22.34722222222222,\n",
       " 29.85185185185185,\n",
       " 22.027397260273972,\n",
       " 19.6144578313253,\n",
       " 23.728571428571428,\n",
       " 29.589285714285715,\n",
       " 22.10810810810811,\n",
       " 19.25,\n",
       " 19.425,\n",
       " 22.70769230769231,\n",
       " 17.62,\n",
       " 26.349206349206348,\n",
       " 22.098591549295776,\n",
       " 21.904109589041095,\n",
       " 22.046875,\n",
       " 17.544554455445546,\n",
       " 28.915254237288135,\n",
       " 31.5609756097561,\n",
       " 18.752808988764045,\n",
       " 30.517241379310345,\n",
       " 27.120689655172413,\n",
       " 22.89189189189189,\n",
       " 18.61764705882353,\n",
       " 20.846153846153847,\n",
       " 21.530864197530864,\n",
       " 23.48611111111111,\n",
       " 23.863636363636363,\n",
       " 19.579545454545453,\n",
       " 31.352941176470587,\n",
       " 18.122448979591837,\n",
       " 27.607142857142858,\n",
       " 22.390625,\n",
       " 24.84722222222222,\n",
       " 23.466666666666665,\n",
       " 26.063492063492063,\n",
       " 18.08235294117647,\n",
       " 22.82278481012658,\n",
       " 21.569767441860463,\n",
       " 31.372549019607842,\n",
       " 20.52,\n",
       " 27.537037037037038,\n",
       " 20.561643835616437,\n",
       " 19.976470588235294,\n",
       " 15.010752688172044,\n",
       " 24.74576271186441,\n",
       " 20.771084337349397,\n",
       " 13.789855072463768,\n",
       " 17.655555555555555,\n",
       " 18.357894736842105,\n",
       " 18.21518987341772,\n",
       " 29.071428571428573,\n",
       " 25.321428571428573,\n",
       " 22.774647887323944,\n",
       " 22.393939393939394,\n",
       " 19.134831460674157,\n",
       " 20.850746268656717,\n",
       " 26.384615384615383,\n",
       " 22.066666666666666,\n",
       " 21.48051948051948,\n",
       " 19.492537313432837,\n",
       " 20.85542168674699,\n",
       " 24.015625,\n",
       " 28.491803278688526,\n",
       " 18.75824175824176,\n",
       " 17.528089887640448,\n",
       " 22.79310344827586,\n",
       " 26.107692307692307,\n",
       " 21.207792207792206,\n",
       " 23.157894736842106,\n",
       " 24.63157894736842,\n",
       " 17.753424657534246,\n",
       " 19.431818181818183,\n",
       " 22.718309859154928,\n",
       " 22.305084745762713,\n",
       " 25,\n",
       " 26.802816901408452,\n",
       " 20.788732394366196,\n",
       " 26.440677966101696,\n",
       " 21.708333333333332,\n",
       " 16.96629213483146,\n",
       " 18.271428571428572,\n",
       " 20.378048780487806,\n",
       " 16.568627450980394,\n",
       " 21.916666666666668,\n",
       " 31.01923076923077,\n",
       " 22.892307692307693,\n",
       " 21.91891891891892,\n",
       " 28.928571428571427,\n",
       " 18.851063829787233,\n",
       " 25.571428571428573,\n",
       " 26.75,\n",
       " 24.285714285714285,\n",
       " 21.485714285714284,\n",
       " 24.295774647887324,\n",
       " 21.82051282051282,\n",
       " 23.671232876712327,\n",
       " 31.433962264150942,\n",
       " 19.80952380952381,\n",
       " 28.314814814814813,\n",
       " 20.416666666666668,\n",
       " 23.936507936507937,\n",
       " 22.17391304347826,\n",
       " 35.38095238095238,\n",
       " 18.50526315789474,\n",
       " 22.643835616438356,\n",
       " 23.514285714285716,\n",
       " 27.114754098360656,\n",
       " 18.853658536585368,\n",
       " 16.59036144578313,\n",
       " 21.420289855072465,\n",
       " 20.950617283950617,\n",
       " 18.724137931034484,\n",
       " 27.46031746031746,\n",
       " 25.09375,\n",
       " 22.175675675675677,\n",
       " 18.050505050505052,\n",
       " 25.529411764705884,\n",
       " 16.752688172043012,\n",
       " 25.944444444444443,\n",
       " 22.545454545454547,\n",
       " 21.7,\n",
       " 25.294117647058822,\n",
       " 30.232142857142858,\n",
       " 24.86764705882353,\n",
       " 26.88679245283019,\n",
       " 26.618181818181817,\n",
       " 28.466666666666665,\n",
       " 22.352941176470587,\n",
       " 27.580645161290324,\n",
       " 28.796610169491526,\n",
       " 24.791044776119403,\n",
       " 16.020408163265305,\n",
       " 26.5,\n",
       " 21.95945945945946,\n",
       " 19.0989010989011,\n",
       " 18.61,\n",
       " 23.291666666666668,\n",
       " 23.171875,\n",
       " 23.675324675324674,\n",
       " 28.017857142857142,\n",
       " 22.684931506849313,\n",
       " 22.281690140845072,\n",
       " 22.40506329113924,\n",
       " 29.264150943396228,\n",
       " 22.95774647887324,\n",
       " 18.795698924731184,\n",
       " 27.3,\n",
       " 16.554455445544555,\n",
       " 28.82758620689655,\n",
       " 22.263157894736842,\n",
       " 37.91304347826087,\n",
       " 19.58823529411765,\n",
       " 32.37735849056604,\n",
       " 28.081967213114755,\n",
       " 28.126984126984127,\n",
       " 26.24590163934426,\n",
       " 24.47761194029851,\n",
       " 22.26027397260274,\n",
       " 25.84375,\n",
       " 18.612244897959183,\n",
       " 18.890243902439025,\n",
       " 24.029411764705884,\n",
       " 21.759493670886076,\n",
       " 23.92207792207792,\n",
       " 28.761904761904763,\n",
       " 20.32,\n",
       " 21.850574712643677,\n",
       " 23.985915492957748,\n",
       " 20.975609756097562,\n",
       " 24.075757575757574,\n",
       " 17.96590909090909,\n",
       " 24.52857142857143,\n",
       " 29.678571428571427,\n",
       " 24.65277777777778,\n",
       " 22.814285714285713,\n",
       " 18.966666666666665,\n",
       " 22.2,\n",
       " 20.354430379746834,\n",
       " 22.465753424657535,\n",
       " 23.640625,\n",
       " 25.0327868852459,\n",
       " 24.859375,\n",
       " 24.140625,\n",
       " 25.196969696969695,\n",
       " 26,\n",
       " 18.182795698924732,\n",
       " 21.69736842105263,\n",
       " 19.12,\n",
       " 18.9247311827957,\n",
       " 19.21518987341772,\n",
       " 24.366197183098592,\n",
       " 29.69090909090909,\n",
       " 27.95,\n",
       " 23.083333333333332,\n",
       " 19.935064935064936,\n",
       " 19.35164835164835,\n",
       " 19.04494382022472,\n",
       " 28.098360655737704,\n",
       " 27.821428571428573,\n",
       " 30.017857142857142,\n",
       " 24.950819672131146,\n",
       " 20.129411764705882,\n",
       " 21.307692307692307,\n",
       " 21.10810810810811,\n",
       " 26.34426229508197,\n",
       " 25.26984126984127,\n",
       " 23.28767123287671,\n",
       " 29.051724137931036,\n",
       " 30.732142857142858,\n",
       " 20.152941176470588,\n",
       " 21.7972972972973,\n",
       " 24,\n",
       " 30.152542372881356,\n",
       " 24.59722222222222,\n",
       " 29.857142857142858,\n",
       " 24.26027397260274,\n",
       " 25.815384615384616,\n",
       " 30.01818181818182,\n",
       " 30.6,\n",
       " 31.442307692307693,\n",
       " 24.82857142857143,\n",
       " 21.0625,\n",
       " 23.407894736842106,\n",
       " 19.27848101265823,\n",
       " 24.901639344262296,\n",
       " 27.868852459016395,\n",
       " 24,\n",
       " 29.24561403508772,\n",
       " 25.454545454545453,\n",
       " 28.38888888888889,\n",
       " 22.794520547945204,\n",
       " 31.28846153846154,\n",
       " 24.439393939393938,\n",
       " 17.902173913043477,\n",
       " 18.847058823529412,\n",
       " 20.741573033707866,\n",
       " 24.043478260869566,\n",
       " 23.857142857142858,\n",
       " 24.451612903225808,\n",
       " 19.88888888888889,\n",
       " 24.17391304347826,\n",
       " 30.280701754385966,\n",
       " 25.681818181818183,\n",
       " 23.43243243243243,\n",
       " 24.4,\n",
       " 22.211267605633804,\n",
       " 20.96590909090909,\n",
       " 21.876712328767123,\n",
       " 25.822580645161292,\n",
       " 25.620689655172413,\n",
       " 23.591549295774648,\n",
       " 29.789473684210527,\n",
       " 27.53968253968254,\n",
       " 28.065573770491802,\n",
       " 30.528301886792452,\n",
       " 25.866666666666667,\n",
       " 25.43076923076923,\n",
       " 21.049382716049383,\n",
       " 29.660714285714285,\n",
       " 25.89855072463768,\n",
       " 23.08108108108108,\n",
       " 15.8875,\n",
       " 33.170212765957444,\n",
       " 23.46153846153846,\n",
       " 19.529411764705884,\n",
       " 31.418181818181818,\n",
       " 33.30612244897959,\n",
       " 20.096385542168676,\n",
       " 22.84722222222222,\n",
       " 26.984615384615385,\n",
       " 21.91891891891892,\n",
       " 21.57894736842105,\n",
       " 20.36046511627907,\n",
       " 22.666666666666668,\n",
       " 23.514705882352942,\n",
       " 30.29090909090909,\n",
       " 23.156626506024097,\n",
       " 24.26027397260274,\n",
       " 20.636363636363637,\n",
       " 25.375,\n",
       " 26,\n",
       " 20.451219512195124,\n",
       " 23.569444444444443,\n",
       " 20.974683544303797,\n",
       " 16.80392156862745,\n",
       " 24.573529411764707,\n",
       " 24.52857142857143,\n",
       " 21.95945945945946,\n",
       " 21.280898876404493,\n",
       " 28.727272727272727,\n",
       " 22.054545454545455,\n",
       " 35.69387755102041,\n",
       " 28.90740740740741,\n",
       " 33.791666666666664,\n",
       " 26.03125,\n",
       " 18.6375,\n",
       " 24.865671641791046,\n",
       " 28.06779661016949,\n",
       " 24.771428571428572,\n",
       " 21.424657534246574,\n",
       " 22.041666666666668,\n",
       " 35.523809523809526,\n",
       " 25.1,\n",
       " 24.893939393939394,\n",
       " 20.907894736842106,\n",
       " 18.8659793814433,\n",
       " 25.848484848484848,\n",
       " 24.296875,\n",
       " 22.208333333333332,\n",
       " 21.192307692307693,\n",
       " 27.678571428571427,\n",
       " 22.506849315068493,\n",
       " 18.333333333333332,\n",
       " 20.51948051948052,\n",
       " 18.875,\n",
       " 26.161290322580644,\n",
       " 27.15,\n",
       " 26.338709677419356,\n",
       " 24.732142857142858,\n",
       " 25.784615384615385,\n",
       " 23.074626865671643,\n",
       " 21.855263157894736,\n",
       " 31.867924528301888,\n",
       " 22.25,\n",
       " 26.983333333333334,\n",
       " 23.01388888888889,\n",
       " 21.210526315789473,\n",
       " 20.71794871794872,\n",
       " 21.518987341772153,\n",
       " 20.850574712643677,\n",
       " 30.43103448275862,\n",
       " 19.27710843373494,\n",
       " 18.340425531914892,\n",
       " 45.97560975609756,\n",
       " 31.67241379310345,\n",
       " 22.3943661971831,\n",
       " 21.963414634146343,\n",
       " 27.482758620689655,\n",
       " 20.75609756097561,\n",
       " 22.08108108108108,\n",
       " 28.366666666666667,\n",
       " 29.387096774193548,\n",
       " 19.985294117647058,\n",
       " 24.210526315789473,\n",
       " 24.322580645161292,\n",
       " 27.852459016393443,\n",
       " 18.84269662921348,\n",
       " 24.053333333333335,\n",
       " 25.104477611940297,\n",
       " 28.120689655172413,\n",
       " 31.26923076923077,\n",
       " 32.18867924528302,\n",
       " 20.258823529411764,\n",
       " 19.012048192771083,\n",
       " 21.942028985507246,\n",
       " 23,\n",
       " 16.519607843137255,\n",
       " 27,\n",
       " 23.785714285714285,\n",
       " 25.042857142857144,\n",
       " 25.241935483870968,\n",
       " 45.13157894736842,\n",
       " 26.770491803278688,\n",
       " 31.425925925925927,\n",
       " 21.527027027027028,\n",
       " 20.85185185185185,\n",
       " 23.65753424657534,\n",
       " 22.25,\n",
       " 31.923076923076923,\n",
       " 23.78082191780822,\n",
       " 19.26530612244898,\n",
       " 26.53968253968254,\n",
       " 22,\n",
       " 20.452380952380953,\n",
       " 25.78125,\n",
       " 22.3943661971831,\n",
       " 24.897058823529413,\n",
       " 19.273972602739725,\n",
       " 21.423076923076923,\n",
       " 28.847457627118644,\n",
       " 31.454545454545453,\n",
       " 22.144736842105264,\n",
       " 27.8135593220339,\n",
       " 26.232142857142858,\n",
       " 28.34426229508197,\n",
       " 17.232558139534884,\n",
       " 23.868852459016395,\n",
       " 22.925,\n",
       " 22.43421052631579,\n",
       " 29.196428571428573,\n",
       " 50.68571428571428,\n",
       " 27.944444444444443,\n",
       " 25.453125,\n",
       " 17.50485436893204,\n",
       " 21.794871794871796,\n",
       " 23.63157894736842,\n",
       " 25.272727272727273,\n",
       " 21.079545454545453,\n",
       " 29.666666666666668,\n",
       " 22.914634146341463,\n",
       " 22.085365853658537,\n",
       " 24,\n",
       " 21.246753246753247,\n",
       " 19.29591836734694,\n",
       " 19.866666666666667,\n",
       " 25.651162790697676,\n",
       " 20.975,\n",
       " 18.11904761904762,\n",
       " 30.63157894736842,\n",
       " 24.323529411764707,\n",
       " 25.696969696969695,\n",
       " 18.75,\n",
       " 17.701923076923077,\n",
       " 29.280701754385966,\n",
       " 22.643835616438356,\n",
       " 18.526881720430108,\n",
       " 19.352941176470587,\n",
       " 27.8,\n",
       " 22.17721518987342,\n",
       " 26.953846153846154,\n",
       " 25.93220338983051,\n",
       " 26.239436619718308,\n",
       " 21.641025641025642,\n",
       " 36.91304347826087,\n",
       " 26.087719298245613,\n",
       " 22.482758620689655,\n",
       " 21.382716049382715,\n",
       " 20.8625,\n",
       " 23.869565217391305,\n",
       " 22.38095238095238,\n",
       " 24.083333333333332,\n",
       " 28.321428571428573,\n",
       " 28.133333333333333,\n",
       " 23.328358208955223,\n",
       " 27.918032786885245,\n",
       " 27.253968253968253,\n",
       " 20.825581395348838,\n",
       " 25.53968253968254,\n",
       " 26.29850746268657,\n",
       " 27.660714285714285,\n",
       " 30.754716981132077,\n",
       " 24.84722222222222,\n",
       " 26.53125,\n",
       " 17.806122448979593,\n",
       " 21.46153846153846,\n",
       " 21.536585365853657,\n",
       " 22.645569620253166,\n",
       " 25.29850746268657,\n",
       " 24.91044776119403,\n",
       " 25,\n",
       " 21.11392405063291,\n",
       " 24.333333333333332,\n",
       " 26.271186440677965,\n",
       " 28.910714285714285,\n",
       " 22.054794520547944,\n",
       " 27.095238095238095,\n",
       " 27.982758620689655,\n",
       " 32.40384615384615,\n",
       " 20.691358024691358,\n",
       " 17.603960396039604,\n",
       " 19.681818181818183,\n",
       " 20.7,\n",
       " 20.847058823529412,\n",
       " 25.27027027027027,\n",
       " 20.55952380952381,\n",
       " 29.189655172413794,\n",
       " 22.203389830508474,\n",
       " 21.74074074074074,\n",
       " 26.37313432835821,\n",
       " 26.885245901639344,\n",
       " 26.095238095238095,\n",
       " 23.263157894736842,\n",
       " 28.804347826086957,\n",
       " 23.28813559322034,\n",
       " 26.71186440677966,\n",
       " 26.328125,\n",
       " 24.12727272727273,\n",
       " 21.460526315789473,\n",
       " 22.11111111111111,\n",
       " 26.265625,\n",
       " 23.986486486486488,\n",
       " 26.85483870967742,\n",
       " 19.34090909090909,\n",
       " 30.482142857142858,\n",
       " 22.64,\n",
       " 32.2037037037037,\n",
       " 22.175,\n",
       " 25.803030303030305,\n",
       " 19.91764705882353,\n",
       " 17.352941176470587]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "import spacy\n",
    "import statistics\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "mean_unique_all_eassy = []\n",
    "\n",
    "for index in df_new.index :\n",
    "    sentences = tokenize.sent_tokenize(df_new['text'][index])\n",
    "    \n",
    "    com_unique_eassy =[] \n",
    "    for i in range(len(sentences)):\n",
    "        doc = nlp(sentences[i])        \n",
    "        \n",
    "        word_type_list =[]\n",
    "        for token in doc:\n",
    "            word_type_list.append(token.dep_)   \n",
    "            \n",
    "        com_unique_eassy.append(len(word_type_list) - word_type_list.count('ROOT'))\n",
    "    \n",
    "    mean_unique_all_eassy.append(statistics.mean(com_unique_eassy))\n",
    "\n",
    "mean_unique_all_eassy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_part_speech(text):\n",
    "    \"\"\"\n",
    "    find the mean of dependencies in a essay\n",
    "    input : string\n",
    "    output : float\n",
    "    \"\"\"\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "\n",
    "    com_unique_essay =[]\n",
    "    for i in range(len(sentences)):\n",
    "        doc = nlp(sentences[i])\n",
    "\n",
    "        word_type_list =[]\n",
    "        for token in doc:\n",
    "            word_type_list.append(token.dep_)\n",
    "\n",
    "        com_unique_essay.append(len(word_type_list) - word_type_list.count('ROOT'))\n",
    "\n",
    "    return statistics.mean(com_unique_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_part_speech(df, col='text'):\n",
    "    \"\"\"\n",
    "    find the mean of dependencies in essay\n",
    "    input : dataframe\n",
    "    output : list of number\n",
    "    \"\"\"\n",
    "\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    mean_unique_all_essay = []\n",
    "\n",
    "    for index in df.index :\n",
    "        sentences = tokenize.sent_tokenize(df[col][index])\n",
    "\n",
    "        com_unique_essay =[]\n",
    "        for i in range(len(sentences)):\n",
    "            doc = nlp(sentences[i])\n",
    "\n",
    "            word_type_list =[]\n",
    "            for token in doc:\n",
    "                word_type_list.append(token.dep_)\n",
    "\n",
    "            com_unique_essay.append(len(word_type_list) - word_type_list.count('ROOT'))\n",
    "\n",
    "        mean_unique_all_essay.append(statistics.mean(com_unique_essay))\n",
    "\n",
    "    mean_unique_all_essay\n",
    "\n",
    "    return mean_unique_all_essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "\n",
    "for index in df.index:\n",
    "    test_list.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.954114</td>\n",
       "      <td>4.374648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.583386</td>\n",
       "      <td>4.659022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.639382</td>\n",
       "      <td>3.787142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.773224</td>\n",
       "      <td>4.493446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.069506</td>\n",
       "      <td>6.025495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       std\n",
       "level                     \n",
       "1      22.954114  4.374648\n",
       "2      23.583386  4.659022\n",
       "3      24.639382  3.787142\n",
       "4      24.773224  4.493446\n",
       "5      29.069506  6.025495"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['complex_part_speech'] = pd.DataFrame(mean_unique_all_eassy)\n",
    "df_new.groupby('level').complex_part_speech.agg(['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "path = os.path.abspath('..')\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the features\n",
    "\n",
    "from essay_grader.text_feature import gen_text_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>level</th>\n",
       "      <th>title_name</th>\n",
       "      <th>vocab_richness</th>\n",
       "      <th>mean_word_syllable</th>\n",
       "      <th>word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>freq_wok_words</th>\n",
       "      <th>freq_aok_words</th>\n",
       "      <th>freq_cliche_words</th>\n",
       "      <th>freq_argument_words</th>\n",
       "      <th>freq_absolute_words</th>\n",
       "      <th>complex_part_speech</th>\n",
       "      <th>vari_part_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the question is asking that in the same discip...</td>\n",
       "      <td>2017</td>\n",
       "      <td>4, 5 - Est_Chen-fzn235-TOK_essay.docx</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Given access to the same facts, how is it poss...</td>\n",
       "      <td>0.209360</td>\n",
       "      <td>1.540025</td>\n",
       "      <td>1525</td>\n",
       "      <td>...</td>\n",
       "      <td>16.223404</td>\n",
       "      <td>788</td>\n",
       "      <td>60.08</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>16.602151</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>our brains seek coherence structure and order ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>7, 6 - Eva GuoTOK_final_final_draft.docx</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Humans are pattern-seeking animals and we are ...</td>\n",
       "      <td>0.344933</td>\n",
       "      <td>1.731380</td>\n",
       "      <td>1575</td>\n",
       "      <td>...</td>\n",
       "      <td>27.155172</td>\n",
       "      <td>724</td>\n",
       "      <td>32.80</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.927273</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in american heritage dictionary of the english...</td>\n",
       "      <td>2017</td>\n",
       "      <td>7, 5 - fzn260_Yessica_Ji_Yuanyi_G12-9_TOKEssay...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Given access to the same facts, how is it poss...</td>\n",
       "      <td>0.398082</td>\n",
       "      <td>1.861711</td>\n",
       "      <td>1208</td>\n",
       "      <td>...</td>\n",
       "      <td>29.463415</td>\n",
       "      <td>528</td>\n",
       "      <td>19.43</td>\n",
       "      <td>8</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.184211</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the statement in the prompt argues that diffic...</td>\n",
       "      <td>2017</td>\n",
       "      <td>8, 1 - James Li TOK_Essay_4th_draft.docx</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>It is only knowledge produced with difficulty ...</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>1.779394</td>\n",
       "      <td>1594</td>\n",
       "      <td>...</td>\n",
       "      <td>26.566667</td>\n",
       "      <td>732</td>\n",
       "      <td>29.33</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>28.017544</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>human are patternseeking animals because patte...</td>\n",
       "      <td>2017</td>\n",
       "      <td>7, 6 - Fzn323_Amy_Wang_Qiaohui_G12_TOK_Essay_D...</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Humans are pattern-seeking animals and we are ...</td>\n",
       "      <td>0.254939</td>\n",
       "      <td>1.554493</td>\n",
       "      <td>1500</td>\n",
       "      <td>...</td>\n",
       "      <td>22.388060</td>\n",
       "      <td>703</td>\n",
       "      <td>52.60</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>22.727273</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>with the rapid change in our environment and s...</td>\n",
       "      <td>2017</td>\n",
       "      <td>5, 3 - Jenny_Ma_TOK_essay.docx</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Should key events in the historical developmen...</td>\n",
       "      <td>0.279128</td>\n",
       "      <td>1.564486</td>\n",
       "      <td>1537</td>\n",
       "      <td>...</td>\n",
       "      <td>21.347222</td>\n",
       "      <td>735</td>\n",
       "      <td>52.81</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>23.707692</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>we are all in the tremendous trend of historic...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1, 3 - fzn255-Evangeline_Shi_Lehan_G12-3_TOK_E...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Should key events in the historical developmen...</td>\n",
       "      <td>0.344346</td>\n",
       "      <td>1.688056</td>\n",
       "      <td>1506</td>\n",
       "      <td>...</td>\n",
       "      <td>23.904762</td>\n",
       "      <td>685</td>\n",
       "      <td>39.76</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24.403226</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>as the time pass inventions or creation have b...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2, 3 - fzn229_Francis_Luo_fzn-229_TOK_essay.docx</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Should key events in the historical developmen...</td>\n",
       "      <td>0.273990</td>\n",
       "      <td>1.530934</td>\n",
       "      <td>1524</td>\n",
       "      <td>...</td>\n",
       "      <td>20.320000</td>\n",
       "      <td>719</td>\n",
       "      <td>56.69</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>21.338028</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pattern is a kind of a consistent phenomenon o...</td>\n",
       "      <td>2017</td>\n",
       "      <td>9, 6 - Vincent_Ru_TOK_Essay.docx</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Humans are pattern-seeking animals and we are ...</td>\n",
       "      <td>0.377505</td>\n",
       "      <td>1.800259</td>\n",
       "      <td>1488</td>\n",
       "      <td>...</td>\n",
       "      <td>27.054545</td>\n",
       "      <td>599</td>\n",
       "      <td>27.07</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.648148</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>traditions are ways of conduct that has been u...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2, 4 - fzn344_Zhao_Tang_Zhao_G12-A_TOKEssay_1....</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>In the production of knowledge, traditions of ...</td>\n",
       "      <td>0.308524</td>\n",
       "      <td>1.547074</td>\n",
       "      <td>1485</td>\n",
       "      <td>...</td>\n",
       "      <td>20.067568</td>\n",
       "      <td>731</td>\n",
       "      <td>55.58</td>\n",
       "      <td>28</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20.520548</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>the ways of people gaining knowledge have chan...</td>\n",
       "      <td>2017</td>\n",
       "      <td>7, 4 - fzn303_Olivia_Song_Zihan_G12C_TOKEssay_...</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>In the production of knowledge, traditions of ...</td>\n",
       "      <td>0.290343</td>\n",
       "      <td>1.746417</td>\n",
       "      <td>1521</td>\n",
       "      <td>...</td>\n",
       "      <td>18.325301</td>\n",
       "      <td>660</td>\n",
       "      <td>40.49</td>\n",
       "      <td>28</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>18.790123</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>knowledge has usually been evaluated according...</td>\n",
       "      <td>2017</td>\n",
       "      <td>4, 1 - Joyce_Shi_ToK_essay.docx</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>It is only knowledge produced with difficulty ...</td>\n",
       "      <td>0.320407</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>1500</td>\n",
       "      <td>...</td>\n",
       "      <td>19.736842</td>\n",
       "      <td>694</td>\n",
       "      <td>48.37</td>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the question in the title is mainly asking abo...</td>\n",
       "      <td>2017</td>\n",
       "      <td>5, 5 - ToK_Essay-Tommy.docx</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Given access to the same facts, how is it poss...</td>\n",
       "      <td>0.342535</td>\n",
       "      <td>1.639900</td>\n",
       "      <td>1535</td>\n",
       "      <td>...</td>\n",
       "      <td>23.615385</td>\n",
       "      <td>677</td>\n",
       "      <td>44.13</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>28.740741</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>facts are something truly exist or happen. peo...</td>\n",
       "      <td>2017</td>\n",
       "      <td>5, 2 - Ann Yu essay.docx</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Facts are needed to establish theories but the...</td>\n",
       "      <td>0.292653</td>\n",
       "      <td>1.513699</td>\n",
       "      <td>1781</td>\n",
       "      <td>...</td>\n",
       "      <td>22.544304</td>\n",
       "      <td>753</td>\n",
       "      <td>55.89</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>20.945946</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>knowledge is a common method to get familiar w...</td>\n",
       "      <td>2017</td>\n",
       "      <td>3, 3 - ToK_essay_Final-fzn231.docx</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Should key events in the historical developmen...</td>\n",
       "      <td>0.291768</td>\n",
       "      <td>1.652542</td>\n",
       "      <td>1619</td>\n",
       "      <td>...</td>\n",
       "      <td>23.463768</td>\n",
       "      <td>753</td>\n",
       "      <td>43.21</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>24.060606</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>throughout of the history there are a lot of c...</td>\n",
       "      <td>2017</td>\n",
       "      <td>1, 3 - fzn263_Kris_Zhang_Jisheng_G12-3_TOKEssa...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Should key events in the historical developmen...</td>\n",
       "      <td>0.261122</td>\n",
       "      <td>1.426177</td>\n",
       "      <td>1480</td>\n",
       "      <td>...</td>\n",
       "      <td>18.271605</td>\n",
       "      <td>792</td>\n",
       "      <td>67.63</td>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>18.375000</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>facts are things truly exist and theories are ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>3, 2 - Jessy_Wang.docx</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Facts are needed to establish theories but the...</td>\n",
       "      <td>0.339689</td>\n",
       "      <td>1.706215</td>\n",
       "      <td>1341</td>\n",
       "      <td>...</td>\n",
       "      <td>20.318182</td>\n",
       "      <td>573</td>\n",
       "      <td>41.87</td>\n",
       "      <td>32</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20.938462</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>the definition of key events and the standards...</td>\n",
       "      <td>2017</td>\n",
       "      <td>5, 3 - Joyce Sun TOK_Final.docx</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Should key events in the historical developmen...</td>\n",
       "      <td>0.323758</td>\n",
       "      <td>1.643926</td>\n",
       "      <td>1593</td>\n",
       "      <td>...</td>\n",
       "      <td>20.423077</td>\n",
       "      <td>739</td>\n",
       "      <td>47.03</td>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>20.714286</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the question in the title implies that our und...</td>\n",
       "      <td>2017</td>\n",
       "      <td>5, 3 - fzn346_Mike_Wang_TOK_essay.docx</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Should key events in the historical developmen...</td>\n",
       "      <td>0.292204</td>\n",
       "      <td>1.656845</td>\n",
       "      <td>1629</td>\n",
       "      <td>...</td>\n",
       "      <td>25.453125</td>\n",
       "      <td>721</td>\n",
       "      <td>40.83</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>24.873016</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>people make values on a lot of knowledge so ho...</td>\n",
       "      <td>2017</td>\n",
       "      <td>3, 1 - TOKEssayCynthia_Chen.docx</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>It is only knowledge produced with difficulty ...</td>\n",
       "      <td>0.278920</td>\n",
       "      <td>1.545630</td>\n",
       "      <td>1477</td>\n",
       "      <td>...</td>\n",
       "      <td>20.232877</td>\n",
       "      <td>727</td>\n",
       "      <td>55.54</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>20.929577</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>the process of achieving knowledge usually inv...</td>\n",
       "      <td>2017</td>\n",
       "      <td>4, 5 - Raymond Yan TOK_essay.docx</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Given access to the same facts, how is it poss...</td>\n",
       "      <td>0.373325</td>\n",
       "      <td>1.719847</td>\n",
       "      <td>1503</td>\n",
       "      <td>...</td>\n",
       "      <td>20.589041</td>\n",
       "      <td>653</td>\n",
       "      <td>40.44</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>20.643836</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>as suggested by michael shermer people are all...</td>\n",
       "      <td>2017</td>\n",
       "      <td>4, 6 - fzn311_Chris_Zhou_Qidi_G12-3_TOKEssay_1...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Humans are pattern-seeking animals and we are ...</td>\n",
       "      <td>0.280374</td>\n",
       "      <td>1.590942</td>\n",
       "      <td>1322</td>\n",
       "      <td>...</td>\n",
       "      <td>18.885714</td>\n",
       "      <td>638</td>\n",
       "      <td>53.07</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>20.796875</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>human seeking behavior is a common action that...</td>\n",
       "      <td>2017</td>\n",
       "      <td>4, 6 - Fzn345_Marco_Wang_Dingwei_G12-3_TOKEssa...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Humans are pattern-seeking animals and we are ...</td>\n",
       "      <td>0.298878</td>\n",
       "      <td>1.575310</td>\n",
       "      <td>1591</td>\n",
       "      <td>...</td>\n",
       "      <td>16.572917</td>\n",
       "      <td>747</td>\n",
       "      <td>56.74</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>16.936842</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>patterns can refer to many things like shapes ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>9, 6 - fzn230_Violet_Xu_Shuyue_G12-9_TOKEssay_...</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>Humans are pattern-seeking animals and we are ...</td>\n",
       "      <td>0.315534</td>\n",
       "      <td>1.700850</td>\n",
       "      <td>1595</td>\n",
       "      <td>...</td>\n",
       "      <td>26.147541</td>\n",
       "      <td>719</td>\n",
       "      <td>36.40</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.947368</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>this essay is about the question should key ev...</td>\n",
       "      <td>2017</td>\n",
       "      <td>5, 3 - Lowey Wang TOK_essay_.docx</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Should key events in the historical developmen...</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>1.540031</td>\n",
       "      <td>1228</td>\n",
       "      <td>...</td>\n",
       "      <td>29.238095</td>\n",
       "      <td>661</td>\n",
       "      <td>46.87</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30.219512</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>the statementfacts are needed to establish the...</td>\n",
       "      <td>2017</td>\n",
       "      <td>6, 2 - fzn272_Dylan_Wang_Zhenyuan_G12_TOKEssay...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Facts are needed to establish theories but the...</td>\n",
       "      <td>0.276110</td>\n",
       "      <td>1.623649</td>\n",
       "      <td>1575</td>\n",
       "      <td>...</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>740</td>\n",
       "      <td>51.71</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17.719101</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>when we are talking about knowledge we usually...</td>\n",
       "      <td>2017</td>\n",
       "      <td>3, 1 - VivianHan.docx.docx</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>It is only knowledge produced with difficulty ...</td>\n",
       "      <td>0.230244</td>\n",
       "      <td>1.594088</td>\n",
       "      <td>1702</td>\n",
       "      <td>...</td>\n",
       "      <td>28.847458</td>\n",
       "      <td>882</td>\n",
       "      <td>42.70</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>29.396552</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>this title claims that the establishment of th...</td>\n",
       "      <td>2017</td>\n",
       "      <td>3, 2 - fzn240_Thomas_Wenhao_Yan_TOK_essay_fina...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Facts are needed to establish theories but the...</td>\n",
       "      <td>0.305851</td>\n",
       "      <td>1.609707</td>\n",
       "      <td>1461</td>\n",
       "      <td>...</td>\n",
       "      <td>24.350000</td>\n",
       "      <td>690</td>\n",
       "      <td>45.94</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>25.103448</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>as our society developed to such a point where...</td>\n",
       "      <td>2017</td>\n",
       "      <td>2, 6 - fzn234_Aiden_Sui_Guangdai_G12-9_TOKEssa...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Humans are pattern-seeking animals and we are ...</td>\n",
       "      <td>0.304321</td>\n",
       "      <td>1.561169</td>\n",
       "      <td>1602</td>\n",
       "      <td>...</td>\n",
       "      <td>21.360000</td>\n",
       "      <td>707</td>\n",
       "      <td>53.08</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>21.405405</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>the question in the title explains that even t...</td>\n",
       "      <td>2017</td>\n",
       "      <td>5, 5 - fzn253_Henry_Lu_Yuhao_G12-9_TOK_essay_2...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Given access to the same facts, how is it poss...</td>\n",
       "      <td>0.262534</td>\n",
       "      <td>1.617251</td>\n",
       "      <td>1758</td>\n",
       "      <td>...</td>\n",
       "      <td>17.405941</td>\n",
       "      <td>834</td>\n",
       "      <td>52.35</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>17.600000</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>interdisciplinary approaches are approaches wh...</td>\n",
       "      <td>2018</td>\n",
       "      <td>4, 1 - gny338-Fred_Liu_Zhiyu_G12-3_TOK_Essay_D...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>The fields of study of academic disciplines ca...</td>\n",
       "      <td>0.346281</td>\n",
       "      <td>1.880165</td>\n",
       "      <td>1158</td>\n",
       "      <td>...</td>\n",
       "      <td>21.849057</td>\n",
       "      <td>484</td>\n",
       "      <td>25.60</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>23.220000</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>does anyone have questions about the point i j...</td>\n",
       "      <td>2018</td>\n",
       "      <td>4, 2 - gyn367_2_1220.docx</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>We know with confidence only when we know litt...</td>\n",
       "      <td>0.347101</td>\n",
       "      <td>1.753623</td>\n",
       "      <td>1305</td>\n",
       "      <td>...</td>\n",
       "      <td>18.913043</td>\n",
       "      <td>544</td>\n",
       "      <td>39.28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>19.028986</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>doubt might be considered as opposite to belie...</td>\n",
       "      <td>2018</td>\n",
       "      <td>7, 2 - Title_2_gny281_1592.docx</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>We know with confidence only when we know litt...</td>\n",
       "      <td>0.301321</td>\n",
       "      <td>1.600240</td>\n",
       "      <td>1591</td>\n",
       "      <td>...</td>\n",
       "      <td>20.662338</td>\n",
       "      <td>722</td>\n",
       "      <td>50.48</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>20.623377</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>production of knowledge requires the collabora...</td>\n",
       "      <td>2018</td>\n",
       "      <td>3, 1 - gny331-1-1575.docx</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>The fields of study of academic disciplines ca...</td>\n",
       "      <td>0.370189</td>\n",
       "      <td>1.970678</td>\n",
       "      <td>1572</td>\n",
       "      <td>...</td>\n",
       "      <td>26.200000</td>\n",
       "      <td>621</td>\n",
       "      <td>13.52</td>\n",
       "      <td>13</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>26.830508</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>in the modern age the amount of knowledge huma...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2, 2 - gny365_Mike_Zhang_Shu_G12-6_TOK_Essay_F...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>We know with confidence only when we know litt...</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>1.592411</td>\n",
       "      <td>1564</td>\n",
       "      <td>...</td>\n",
       "      <td>22.342857</td>\n",
       "      <td>746</td>\n",
       "      <td>49.44</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>22.471429</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>commonly doubt is regarded as a cause of misun...</td>\n",
       "      <td>2018</td>\n",
       "      <td>5, 2 - gny299_title2_1569words.docx</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>We know with confidence only when we know litt...</td>\n",
       "      <td>0.366154</td>\n",
       "      <td>1.716923</td>\n",
       "      <td>1560</td>\n",
       "      <td>...</td>\n",
       "      <td>26.440678</td>\n",
       "      <td>687</td>\n",
       "      <td>34.75</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>26.559322</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>consensus is peoples agreement and acceptance ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>4, 6 - gny394_-Freeze_Shi_Jiating_G12-6_TOK_Es...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Robust knowledge requires both consensus and d...</td>\n",
       "      <td>0.316034</td>\n",
       "      <td>1.748257</td>\n",
       "      <td>1232</td>\n",
       "      <td>...</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>584</td>\n",
       "      <td>39.39</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>22.545455</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>the statement above refers to the relation bet...</td>\n",
       "      <td>2018</td>\n",
       "      <td>1, 2 - gny309-Royer_Zhang_Ruyue_G12-6TOK_Essay...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>We know with confidence only when we know litt...</td>\n",
       "      <td>0.330417</td>\n",
       "      <td>1.639973</td>\n",
       "      <td>1402</td>\n",
       "      <td>...</td>\n",
       "      <td>20.318841</td>\n",
       "      <td>669</td>\n",
       "      <td>47.47</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>21.298507</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>the acquisition of knowledge is easily affecte...</td>\n",
       "      <td>2018</td>\n",
       "      <td>6, 2 - gny269_2_1598.docx</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>We know with confidence only when we know litt...</td>\n",
       "      <td>0.271084</td>\n",
       "      <td>1.683133</td>\n",
       "      <td>1591</td>\n",
       "      <td>...</td>\n",
       "      <td>26.966102</td>\n",
       "      <td>707</td>\n",
       "      <td>37.07</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>27.637931</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>human beings have been challenging themselves ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>6, 5 - ToK_Essay_Anda_ToK_1_Final.docx</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>The quality of knowledge produced by an academ...</td>\n",
       "      <td>0.363005</td>\n",
       "      <td>1.854167</td>\n",
       "      <td>1525</td>\n",
       "      <td>...</td>\n",
       "      <td>24.206349</td>\n",
       "      <td>678</td>\n",
       "      <td>25.40</td>\n",
       "      <td>13</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>25.163934</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>condemned by their own greed humans have been ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>3, 5 - gny286-title5-1557.docx</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>The quality of knowledge produced by an academ...</td>\n",
       "      <td>0.307645</td>\n",
       "      <td>1.801480</td>\n",
       "      <td>1556</td>\n",
       "      <td>...</td>\n",
       "      <td>24.312500</td>\n",
       "      <td>677</td>\n",
       "      <td>29.75</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>24.730159</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>the quality of knowledge seems an unlikely way...</td>\n",
       "      <td>2018</td>\n",
       "      <td>3, 2 - gny354_2_1599.docx</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>We know with confidence only when we know litt...</td>\n",
       "      <td>0.316137</td>\n",
       "      <td>1.751650</td>\n",
       "      <td>1590</td>\n",
       "      <td>...</td>\n",
       "      <td>22.083333</td>\n",
       "      <td>691</td>\n",
       "      <td>36.23</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>nowadays because of a sudden change in the sit...</td>\n",
       "      <td>2018</td>\n",
       "      <td>3, 5 - gny297-Marshall_Wu_Yuxi_G12-6_TOK_Essay...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>The quality of knowledge produced by an academ...</td>\n",
       "      <td>0.307932</td>\n",
       "      <td>1.699844</td>\n",
       "      <td>1204</td>\n",
       "      <td>...</td>\n",
       "      <td>25.617021</td>\n",
       "      <td>597</td>\n",
       "      <td>37.03</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>27.021739</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>just like what heraclitus an ancient greek phi...</td>\n",
       "      <td>2018</td>\n",
       "      <td>3, 5 - gny358-Zane_Cui_Yuchen_G12-3_TOK_Essay_...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>The quality of knowledge produced by an academ...</td>\n",
       "      <td>0.291111</td>\n",
       "      <td>1.744444</td>\n",
       "      <td>1295</td>\n",
       "      <td>...</td>\n",
       "      <td>21.583333</td>\n",
       "      <td>595</td>\n",
       "      <td>37.35</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>21.583333</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>as the total amount of knowledge keeps increas...</td>\n",
       "      <td>2018</td>\n",
       "      <td>8, 1 - gny318-James_Wu_Shixin_G12-3_TOK_Essay_...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>The fields of study of academic disciplines ca...</td>\n",
       "      <td>0.318425</td>\n",
       "      <td>1.806409</td>\n",
       "      <td>1432</td>\n",
       "      <td>...</td>\n",
       "      <td>23.475410</td>\n",
       "      <td>620</td>\n",
       "      <td>30.19</td>\n",
       "      <td>9</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>24.423729</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>suspension of disbelief the key factor enriche...</td>\n",
       "      <td>2018</td>\n",
       "      <td>4, 4 -  gny360-Lancelot_Li_HaoWei_G12-6_TOK_Es...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>'Suspension of disbelief' is an essential feat...</td>\n",
       "      <td>0.306949</td>\n",
       "      <td>1.687613</td>\n",
       "      <td>1569</td>\n",
       "      <td>...</td>\n",
       "      <td>24.138462</td>\n",
       "      <td>714</td>\n",
       "      <td>39.56</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>24.984375</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>academic disciplines are developed by people a...</td>\n",
       "      <td>2018</td>\n",
       "      <td>4, 1 - gny321-Marina_He_Muyun_G12-3_TOK_Essay_...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>The fields of study of academic disciplines ca...</td>\n",
       "      <td>0.317241</td>\n",
       "      <td>1.897318</td>\n",
       "      <td>1243</td>\n",
       "      <td>...</td>\n",
       "      <td>22.600000</td>\n",
       "      <td>491</td>\n",
       "      <td>23.38</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>22.890909</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>confidence and doubt could be two things that ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>4, 2 - Connie_Huang_TOK_Essay_Final_Draft.docx</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>We know with confidence only when we know litt...</td>\n",
       "      <td>0.315755</td>\n",
       "      <td>1.630859</td>\n",
       "      <td>1479</td>\n",
       "      <td>...</td>\n",
       "      <td>22.074627</td>\n",
       "      <td>729</td>\n",
       "      <td>46.46</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>22.560606</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>when we are watching a play in a theater we ar...</td>\n",
       "      <td>2018</td>\n",
       "      <td>7, 4 - gny304_04_1414.docx</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>'Suspension of disbelief' is an essential feat...</td>\n",
       "      <td>0.312455</td>\n",
       "      <td>1.750180</td>\n",
       "      <td>1407</td>\n",
       "      <td>...</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>604</td>\n",
       "      <td>36.10</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>production of knowledge and its acquisition or...</td>\n",
       "      <td>2018</td>\n",
       "      <td>4, 1 - gny261_title1_1591.docx</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>The fields of study of academic disciplines ca...</td>\n",
       "      <td>0.300912</td>\n",
       "      <td>1.670517</td>\n",
       "      <td>1592</td>\n",
       "      <td>...</td>\n",
       "      <td>22.742857</td>\n",
       "      <td>752</td>\n",
       "      <td>42.43</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>25.523810</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>during our learning process doubts are interpr...</td>\n",
       "      <td>2018</td>\n",
       "      <td>3, 2 -  Vivian.Liu_TOK_essay_final_draft.docx</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>We know with confidence only when we know litt...</td>\n",
       "      <td>0.341048</td>\n",
       "      <td>1.683922</td>\n",
       "      <td>1576</td>\n",
       "      <td>...</td>\n",
       "      <td>25.419355</td>\n",
       "      <td>752</td>\n",
       "      <td>38.57</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>26.163934</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>we humans are dynamic creatures living in a co...</td>\n",
       "      <td>2018</td>\n",
       "      <td>4, 3 - gny270-Angela_Zheng_Xuanqi_G12-3_TOK_Es...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Without the assumption of the existence of uni...</td>\n",
       "      <td>0.341963</td>\n",
       "      <td>1.769416</td>\n",
       "      <td>1593</td>\n",
       "      <td>...</td>\n",
       "      <td>25.693548</td>\n",
       "      <td>772</td>\n",
       "      <td>31.06</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>25.822581</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>some knowledge claims are shared and accepted ...</td>\n",
       "      <td>2018</td>\n",
       "      <td>5, 6 - gny305-Amethyst_Yan_Chengfei_G12-6_TOK_...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Robust knowledge requires both consensus and d...</td>\n",
       "      <td>0.311031</td>\n",
       "      <td>1.805304</td>\n",
       "      <td>1571</td>\n",
       "      <td>...</td>\n",
       "      <td>17.651685</td>\n",
       "      <td>669</td>\n",
       "      <td>36.19</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>18.406977</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>the continued development of rules and discipl...</td>\n",
       "      <td>2018</td>\n",
       "      <td>4, 5 - gny372_‘The_quality_of_knowledge_produc...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>The quality of knowledge produced by an academ...</td>\n",
       "      <td>0.329099</td>\n",
       "      <td>1.681791</td>\n",
       "      <td>1597</td>\n",
       "      <td>...</td>\n",
       "      <td>28.517857</td>\n",
       "      <td>740</td>\n",
       "      <td>35.61</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>28.535714</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>humans are normally attracted to exploring kno...</td>\n",
       "      <td>2018</td>\n",
       "      <td>5, 1 - Sophie WuToK_Essay_Third_Draft.docx</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>The fields of study of academic disciplines ca...</td>\n",
       "      <td>0.350760</td>\n",
       "      <td>1.834043</td>\n",
       "      <td>1571</td>\n",
       "      <td>...</td>\n",
       "      <td>21.229730</td>\n",
       "      <td>678</td>\n",
       "      <td>30.13</td>\n",
       "      <td>7</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>21.888889</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>strong and valid knowledge is not generated on...</td>\n",
       "      <td>2018</td>\n",
       "      <td>5, 6 - gny293-Billy_Mai_Junhao_G12-3_TOK_Essay...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Robust knowledge requires both consensus and d...</td>\n",
       "      <td>0.292373</td>\n",
       "      <td>1.691283</td>\n",
       "      <td>1597</td>\n",
       "      <td>...</td>\n",
       "      <td>29.036364</td>\n",
       "      <td>734</td>\n",
       "      <td>34.28</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>29.648148</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>smartphones apollo project and genetic modific...</td>\n",
       "      <td>2018</td>\n",
       "      <td>2, 5 - gny275-Hiram_Ma_Jun_G12-3_TOK_Essay_Dra...</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The quality of knowledge produced by an academ...</td>\n",
       "      <td>0.308428</td>\n",
       "      <td>1.884638</td>\n",
       "      <td>1596</td>\n",
       "      <td>...</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>703</td>\n",
       "      <td>24.25</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>23.246377</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>uniformities are common patterns across the hu...</td>\n",
       "      <td>2018</td>\n",
       "      <td>6, 3 - gny260_3_1599.docx</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Without the assumption of the existence of uni...</td>\n",
       "      <td>0.323494</td>\n",
       "      <td>1.816867</td>\n",
       "      <td>1591</td>\n",
       "      <td>...</td>\n",
       "      <td>24.106061</td>\n",
       "      <td>690</td>\n",
       "      <td>28.66</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>24.227273</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>there are a thousand hamlets in a thousand peo...</td>\n",
       "      <td>2018</td>\n",
       "      <td>4, 6 - gny370-6-1594.docx</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Robust knowledge requires both consensus and d...</td>\n",
       "      <td>0.340759</td>\n",
       "      <td>1.739314</td>\n",
       "      <td>1573</td>\n",
       "      <td>...</td>\n",
       "      <td>17.674157</td>\n",
       "      <td>675</td>\n",
       "      <td>41.75</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>18.928571</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>have you ever imaged how knowledge can exist i...</td>\n",
       "      <td>2018</td>\n",
       "      <td>3, 3 - gny362_Howell_Lv_Haoyu_tok_essay_final_...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Without the assumption of the existence of uni...</td>\n",
       "      <td>0.258584</td>\n",
       "      <td>1.559916</td>\n",
       "      <td>1343</td>\n",
       "      <td>...</td>\n",
       "      <td>16.787500</td>\n",
       "      <td>709</td>\n",
       "      <td>57.83</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>17.649351</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  year  \\\n",
       "0    the question is asking that in the same discip...  2017   \n",
       "1    our brains seek coherence structure and order ...  2017   \n",
       "2    in american heritage dictionary of the english...  2017   \n",
       "3    the statement in the prompt argues that diffic...  2017   \n",
       "4    human are patternseeking animals because patte...  2017   \n",
       "5    with the rapid change in our environment and s...  2017   \n",
       "6    we are all in the tremendous trend of historic...  2017   \n",
       "7    as the time pass inventions or creation have b...  2017   \n",
       "8    pattern is a kind of a consistent phenomenon o...  2017   \n",
       "9    traditions are ways of conduct that has been u...  2017   \n",
       "10   the ways of people gaining knowledge have chan...  2017   \n",
       "11   knowledge has usually been evaluated according...  2017   \n",
       "12   the question in the title is mainly asking abo...  2017   \n",
       "13   facts are something truly exist or happen. peo...  2017   \n",
       "14   knowledge is a common method to get familiar w...  2017   \n",
       "15   throughout of the history there are a lot of c...  2017   \n",
       "16   facts are things truly exist and theories are ...  2017   \n",
       "17   the definition of key events and the standards...  2017   \n",
       "18   the question in the title implies that our und...  2017   \n",
       "19   people make values on a lot of knowledge so ho...  2017   \n",
       "20   the process of achieving knowledge usually inv...  2017   \n",
       "21   as suggested by michael shermer people are all...  2017   \n",
       "22   human seeking behavior is a common action that...  2017   \n",
       "23   patterns can refer to many things like shapes ...  2017   \n",
       "24   this essay is about the question should key ev...  2017   \n",
       "25   the statementfacts are needed to establish the...  2017   \n",
       "26   when we are talking about knowledge we usually...  2017   \n",
       "27   this title claims that the establishment of th...  2017   \n",
       "28   as our society developed to such a point where...  2017   \n",
       "29   the question in the title explains that even t...  2017   \n",
       "..                                                 ...   ...   \n",
       "467  interdisciplinary approaches are approaches wh...  2018   \n",
       "468  does anyone have questions about the point i j...  2018   \n",
       "469  doubt might be considered as opposite to belie...  2018   \n",
       "470  production of knowledge requires the collabora...  2018   \n",
       "471  in the modern age the amount of knowledge huma...  2018   \n",
       "472  commonly doubt is regarded as a cause of misun...  2018   \n",
       "473  consensus is peoples agreement and acceptance ...  2018   \n",
       "474  the statement above refers to the relation bet...  2018   \n",
       "475  the acquisition of knowledge is easily affecte...  2018   \n",
       "476  human beings have been challenging themselves ...  2018   \n",
       "477  condemned by their own greed humans have been ...  2018   \n",
       "478  the quality of knowledge seems an unlikely way...  2018   \n",
       "479  nowadays because of a sudden change in the sit...  2018   \n",
       "480  just like what heraclitus an ancient greek phi...  2018   \n",
       "481  as the total amount of knowledge keeps increas...  2018   \n",
       "482  suspension of disbelief the key factor enriche...  2018   \n",
       "483  academic disciplines are developed by people a...  2018   \n",
       "484  confidence and doubt could be two things that ...  2018   \n",
       "485  when we are watching a play in a theater we ar...  2018   \n",
       "486  production of knowledge and its acquisition or...  2018   \n",
       "487  during our learning process doubts are interpr...  2018   \n",
       "488  we humans are dynamic creatures living in a co...  2018   \n",
       "489  some knowledge claims are shared and accepted ...  2018   \n",
       "490  the continued development of rules and discipl...  2018   \n",
       "491  humans are normally attracted to exploring kno...  2018   \n",
       "492  strong and valid knowledge is not generated on...  2018   \n",
       "493  smartphones apollo project and genetic modific...  2018   \n",
       "494  uniformities are common patterns across the hu...  2018   \n",
       "495  there are a thousand hamlets in a thousand peo...  2018   \n",
       "496  have you ever imaged how knowledge can exist i...  2018   \n",
       "\n",
       "                                                  name  title  score  level  \\\n",
       "0                4, 5 - Est_Chen-fzn235-TOK_essay.docx      5      4      2   \n",
       "1             7, 6 - Eva GuoTOK_final_final_draft.docx      6      7      4   \n",
       "2    7, 5 - fzn260_Yessica_Ji_Yuanyi_G12-9_TOKEssay...      5      7      4   \n",
       "3             8, 1 - James Li TOK_Essay_4th_draft.docx      1      8      4   \n",
       "4    7, 6 - Fzn323_Amy_Wang_Qiaohui_G12_TOK_Essay_D...      6      7      4   \n",
       "5                       5, 3 - Jenny_Ma_TOK_essay.docx      3      5      3   \n",
       "6    1, 3 - fzn255-Evangeline_Shi_Lehan_G12-3_TOK_E...      3      1      1   \n",
       "7     2, 3 - fzn229_Francis_Luo_fzn-229_TOK_essay.docx      3      2      1   \n",
       "8                     9, 6 - Vincent_Ru_TOK_Essay.docx      6      9      5   \n",
       "9    2, 4 - fzn344_Zhao_Tang_Zhao_G12-A_TOKEssay_1....      4      2      1   \n",
       "10   7, 4 - fzn303_Olivia_Song_Zihan_G12C_TOKEssay_...      4      7      4   \n",
       "11                     4, 1 - Joyce_Shi_ToK_essay.docx      1      4      2   \n",
       "12                         5, 5 - ToK_Essay-Tommy.docx      5      5      3   \n",
       "13                            5, 2 - Ann Yu essay.docx      2      5      3   \n",
       "14                  3, 3 - ToK_essay_Final-fzn231.docx      3      3      2   \n",
       "15   1, 3 - fzn263_Kris_Zhang_Jisheng_G12-3_TOKEssa...      3      1      1   \n",
       "16                              3, 2 - Jessy_Wang.docx      2      3      2   \n",
       "17                     5, 3 - Joyce Sun TOK_Final.docx      3      5      3   \n",
       "18              5, 3 - fzn346_Mike_Wang_TOK_essay.docx      3      5      3   \n",
       "19                    3, 1 - TOKEssayCynthia_Chen.docx      1      3      2   \n",
       "20                   4, 5 - Raymond Yan TOK_essay.docx      5      4      2   \n",
       "21   4, 6 - fzn311_Chris_Zhou_Qidi_G12-3_TOKEssay_1...      6      4      2   \n",
       "22   4, 6 - Fzn345_Marco_Wang_Dingwei_G12-3_TOKEssa...      6      4      2   \n",
       "23   9, 6 - fzn230_Violet_Xu_Shuyue_G12-9_TOKEssay_...      6      9      5   \n",
       "24                   5, 3 - Lowey Wang TOK_essay_.docx      3      5      3   \n",
       "25   6, 2 - fzn272_Dylan_Wang_Zhenyuan_G12_TOKEssay...      2      6      3   \n",
       "26                          3, 1 - VivianHan.docx.docx      1      3      2   \n",
       "27   3, 2 - fzn240_Thomas_Wenhao_Yan_TOK_essay_fina...      2      3      2   \n",
       "28   2, 6 - fzn234_Aiden_Sui_Guangdai_G12-9_TOKEssa...      6      2      1   \n",
       "29   5, 5 - fzn253_Henry_Lu_Yuhao_G12-9_TOK_essay_2...      5      5      3   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "467  4, 1 - gny338-Fred_Liu_Zhiyu_G12-3_TOK_Essay_D...      1      4      2   \n",
       "468                          4, 2 - gyn367_2_1220.docx      2      4      2   \n",
       "469                    7, 2 - Title_2_gny281_1592.docx      2      7      4   \n",
       "470                          3, 1 - gny331-1-1575.docx      1      3      2   \n",
       "471  2, 2 - gny365_Mike_Zhang_Shu_G12-6_TOK_Essay_F...      2      2      1   \n",
       "472                5, 2 - gny299_title2_1569words.docx      2      5      3   \n",
       "473  4, 6 - gny394_-Freeze_Shi_Jiating_G12-6_TOK_Es...      6      4      2   \n",
       "474  1, 2 - gny309-Royer_Zhang_Ruyue_G12-6TOK_Essay...      2      1      1   \n",
       "475                          6, 2 - gny269_2_1598.docx      2      6      3   \n",
       "476             6, 5 - ToK_Essay_Anda_ToK_1_Final.docx      5      6      3   \n",
       "477                     3, 5 - gny286-title5-1557.docx      5      3      2   \n",
       "478                          3, 2 - gny354_2_1599.docx      2      3      2   \n",
       "479  3, 5 - gny297-Marshall_Wu_Yuxi_G12-6_TOK_Essay...      5      3      2   \n",
       "480  3, 5 - gny358-Zane_Cui_Yuchen_G12-3_TOK_Essay_...      5      3      2   \n",
       "481  8, 1 - gny318-James_Wu_Shixin_G12-3_TOK_Essay_...      1      8      4   \n",
       "482  4, 4 -  gny360-Lancelot_Li_HaoWei_G12-6_TOK_Es...      4      4      2   \n",
       "483  4, 1 - gny321-Marina_He_Muyun_G12-3_TOK_Essay_...      1      4      2   \n",
       "484     4, 2 - Connie_Huang_TOK_Essay_Final_Draft.docx      2      4      2   \n",
       "485                         7, 4 - gny304_04_1414.docx      4      7      4   \n",
       "486                     4, 1 - gny261_title1_1591.docx      1      4      2   \n",
       "487      3, 2 -  Vivian.Liu_TOK_essay_final_draft.docx      2      3      2   \n",
       "488  4, 3 - gny270-Angela_Zheng_Xuanqi_G12-3_TOK_Es...      3      4      2   \n",
       "489  5, 6 - gny305-Amethyst_Yan_Chengfei_G12-6_TOK_...      6      5      3   \n",
       "490  4, 5 - gny372_‘The_quality_of_knowledge_produc...      5      4      2   \n",
       "491         5, 1 - Sophie WuToK_Essay_Third_Draft.docx      1      5      3   \n",
       "492  5, 6 - gny293-Billy_Mai_Junhao_G12-3_TOK_Essay...      6      5      3   \n",
       "493  2, 5 - gny275-Hiram_Ma_Jun_G12-3_TOK_Essay_Dra...      5      2      1   \n",
       "494                          6, 3 - gny260_3_1599.docx      3      6      3   \n",
       "495                          4, 6 - gny370-6-1594.docx      6      4      2   \n",
       "496  3, 3 - gny362_Howell_Lv_Haoyu_tok_essay_final_...      3      3      2   \n",
       "\n",
       "                                            title_name  vocab_richness  \\\n",
       "0    Given access to the same facts, how is it poss...        0.209360   \n",
       "1    Humans are pattern-seeking animals and we are ...        0.344933   \n",
       "2    Given access to the same facts, how is it poss...        0.398082   \n",
       "3    It is only knowledge produced with difficulty ...        0.386667   \n",
       "4    Humans are pattern-seeking animals and we are ...        0.254939   \n",
       "5    Should key events in the historical developmen...        0.279128   \n",
       "6    Should key events in the historical developmen...        0.344346   \n",
       "7    Should key events in the historical developmen...        0.273990   \n",
       "8    Humans are pattern-seeking animals and we are ...        0.377505   \n",
       "9    In the production of knowledge, traditions of ...        0.308524   \n",
       "10   In the production of knowledge, traditions of ...        0.290343   \n",
       "11   It is only knowledge produced with difficulty ...        0.320407   \n",
       "12   Given access to the same facts, how is it poss...        0.342535   \n",
       "13   Facts are needed to establish theories but the...        0.292653   \n",
       "14   Should key events in the historical developmen...        0.291768   \n",
       "15   Should key events in the historical developmen...        0.261122   \n",
       "16   Facts are needed to establish theories but the...        0.339689   \n",
       "17   Should key events in the historical developmen...        0.323758   \n",
       "18   Should key events in the historical developmen...        0.292204   \n",
       "19   It is only knowledge produced with difficulty ...        0.278920   \n",
       "20   Given access to the same facts, how is it poss...        0.373325   \n",
       "21   Humans are pattern-seeking animals and we are ...        0.280374   \n",
       "22   Humans are pattern-seeking animals and we are ...        0.298878   \n",
       "23   Humans are pattern-seeking animals and we are ...        0.315534   \n",
       "24   Should key events in the historical developmen...        0.230769   \n",
       "25   Facts are needed to establish theories but the...        0.276110   \n",
       "26   It is only knowledge produced with difficulty ...        0.230244   \n",
       "27   Facts are needed to establish theories but the...        0.305851   \n",
       "28   Humans are pattern-seeking animals and we are ...        0.304321   \n",
       "29   Given access to the same facts, how is it poss...        0.262534   \n",
       "..                                                 ...             ...   \n",
       "467  The fields of study of academic disciplines ca...        0.346281   \n",
       "468  We know with confidence only when we know litt...        0.347101   \n",
       "469  We know with confidence only when we know litt...        0.301321   \n",
       "470  The fields of study of academic disciplines ca...        0.370189   \n",
       "471  We know with confidence only when we know litt...        0.290698   \n",
       "472  We know with confidence only when we know litt...        0.366154   \n",
       "473  Robust knowledge requires both consensus and d...        0.316034   \n",
       "474  We know with confidence only when we know litt...        0.330417   \n",
       "475  We know with confidence only when we know litt...        0.271084   \n",
       "476  The quality of knowledge produced by an academ...        0.363005   \n",
       "477  The quality of knowledge produced by an academ...        0.307645   \n",
       "478  We know with confidence only when we know litt...        0.316137   \n",
       "479  The quality of knowledge produced by an academ...        0.307932   \n",
       "480  The quality of knowledge produced by an academ...        0.291111   \n",
       "481  The fields of study of academic disciplines ca...        0.318425   \n",
       "482  'Suspension of disbelief' is an essential feat...        0.306949   \n",
       "483  The fields of study of academic disciplines ca...        0.317241   \n",
       "484  We know with confidence only when we know litt...        0.315755   \n",
       "485  'Suspension of disbelief' is an essential feat...        0.312455   \n",
       "486  The fields of study of academic disciplines ca...        0.300912   \n",
       "487  We know with confidence only when we know litt...        0.341048   \n",
       "488  Without the assumption of the existence of uni...        0.341963   \n",
       "489  Robust knowledge requires both consensus and d...        0.311031   \n",
       "490  The quality of knowledge produced by an academ...        0.329099   \n",
       "491  The fields of study of academic disciplines ca...        0.350760   \n",
       "492  Robust knowledge requires both consensus and d...        0.292373   \n",
       "493  The quality of knowledge produced by an academ...        0.308428   \n",
       "494  Without the assumption of the existence of uni...        0.323494   \n",
       "495  Robust knowledge requires both consensus and d...        0.340759   \n",
       "496  Without the assumption of the existence of uni...        0.258584   \n",
       "\n",
       "     mean_word_syllable  word_count  ...  avg_sentence_length  \\\n",
       "0              1.540025        1525  ...            16.223404   \n",
       "1              1.731380        1575  ...            27.155172   \n",
       "2              1.861711        1208  ...            29.463415   \n",
       "3              1.779394        1594  ...            26.566667   \n",
       "4              1.554493        1500  ...            22.388060   \n",
       "5              1.564486        1537  ...            21.347222   \n",
       "6              1.688056        1506  ...            23.904762   \n",
       "7              1.530934        1524  ...            20.320000   \n",
       "8              1.800259        1488  ...            27.054545   \n",
       "9              1.547074        1485  ...            20.067568   \n",
       "10             1.746417        1521  ...            18.325301   \n",
       "11             1.636364        1500  ...            19.736842   \n",
       "12             1.639900        1535  ...            23.615385   \n",
       "13             1.513699        1781  ...            22.544304   \n",
       "14             1.652542        1619  ...            23.463768   \n",
       "15             1.426177        1480  ...            18.271605   \n",
       "16             1.706215        1341  ...            20.318182   \n",
       "17             1.643926        1593  ...            20.423077   \n",
       "18             1.656845        1629  ...            25.453125   \n",
       "19             1.545630        1477  ...            20.232877   \n",
       "20             1.719847        1503  ...            20.589041   \n",
       "21             1.590942        1322  ...            18.885714   \n",
       "22             1.575310        1591  ...            16.572917   \n",
       "23             1.700850        1595  ...            26.147541   \n",
       "24             1.540031        1228  ...            29.238095   \n",
       "25             1.623649        1575  ...            17.500000   \n",
       "26             1.594088        1702  ...            28.847458   \n",
       "27             1.609707        1461  ...            24.350000   \n",
       "28             1.561169        1602  ...            21.360000   \n",
       "29             1.617251        1758  ...            17.405941   \n",
       "..                  ...         ...  ...                  ...   \n",
       "467            1.880165        1158  ...            21.849057   \n",
       "468            1.753623        1305  ...            18.913043   \n",
       "469            1.600240        1591  ...            20.662338   \n",
       "470            1.970678        1572  ...            26.200000   \n",
       "471            1.592411        1564  ...            22.342857   \n",
       "472            1.716923        1560  ...            26.440678   \n",
       "473            1.748257        1232  ...            19.250000   \n",
       "474            1.639973        1402  ...            20.318841   \n",
       "475            1.683133        1591  ...            26.966102   \n",
       "476            1.854167        1525  ...            24.206349   \n",
       "477            1.801480        1556  ...            24.312500   \n",
       "478            1.751650        1590  ...            22.083333   \n",
       "479            1.699844        1204  ...            25.617021   \n",
       "480            1.744444        1295  ...            21.583333   \n",
       "481            1.806409        1432  ...            23.475410   \n",
       "482            1.687613        1569  ...            24.138462   \n",
       "483            1.897318        1243  ...            22.600000   \n",
       "484            1.630859        1479  ...            22.074627   \n",
       "485            1.750180        1407  ...            22.333333   \n",
       "486            1.670517        1592  ...            22.742857   \n",
       "487            1.683922        1576  ...            25.419355   \n",
       "488            1.769416        1593  ...            25.693548   \n",
       "489            1.805304        1571  ...            17.651685   \n",
       "490            1.681791        1597  ...            28.517857   \n",
       "491            1.834043        1571  ...            21.229730   \n",
       "492            1.691283        1597  ...            29.036364   \n",
       "493            1.884638        1596  ...            22.800000   \n",
       "494            1.816867        1591  ...            24.106061   \n",
       "495            1.739314        1573  ...            17.674157   \n",
       "496            1.559916        1343  ...            16.787500   \n",
       "\n",
       "     count_stopwords  flesch_reading_ease  freq_wok_words  freq_aok_words  \\\n",
       "0                788                60.08              25              52   \n",
       "1                724                32.80              11               7   \n",
       "2                528                19.43               8              23   \n",
       "3                732                29.33               2              14   \n",
       "4                703                52.60               2              38   \n",
       "5                735                52.81               8              39   \n",
       "6                685                39.76               4              28   \n",
       "7                719                56.69               3              12   \n",
       "8                599                27.07              23               5   \n",
       "9                731                55.58              28              19   \n",
       "10               660                40.49              28              38   \n",
       "11               694                48.37               6              47   \n",
       "12               677                44.13               4              20   \n",
       "13               753                55.89               4              16   \n",
       "14               753                43.21               6              23   \n",
       "15               792                67.63               9              40   \n",
       "16               573                41.87              32              34   \n",
       "17               739                47.03              20              55   \n",
       "18               721                40.83               4              46   \n",
       "19               727                55.54               8              45   \n",
       "20               653                40.44              23               8   \n",
       "21               638                53.07               8              13   \n",
       "22               747                56.74              11               9   \n",
       "23               719                36.40               9              20   \n",
       "24               661                46.87               0              14   \n",
       "25               740                51.71              23              26   \n",
       "26               882                42.70               2              11   \n",
       "27               690                45.94              20               9   \n",
       "28               707                53.08              19              15   \n",
       "29               834                52.35               2              21   \n",
       "..               ...                  ...             ...             ...   \n",
       "467              484                25.60               0               8   \n",
       "468              544                39.28               0               6   \n",
       "469              722                50.48              14               3   \n",
       "470              621                13.52              13              27   \n",
       "471              746                49.44               6              23   \n",
       "472              687                34.75               7              11   \n",
       "473              584                39.39               1              34   \n",
       "474              669                47.47              17              28   \n",
       "475              707                37.07               2              16   \n",
       "476              678                25.40              13              59   \n",
       "477              677                29.75               5              24   \n",
       "478              691                36.23              10              13   \n",
       "479              597                37.03               0              29   \n",
       "480              595                37.35               0               5   \n",
       "481              620                30.19               9              49   \n",
       "482              714                39.56               3              64   \n",
       "483              491                23.38               6              21   \n",
       "484              729                46.46               1              10   \n",
       "485              604                36.10               9               4   \n",
       "486              752                42.43               9              10   \n",
       "487              752                38.57               9               9   \n",
       "488              772                31.06               0              20   \n",
       "489              669                36.19               2               7   \n",
       "490              740                35.61               9              12   \n",
       "491              678                30.13               7              29   \n",
       "492              734                34.28              10              15   \n",
       "493              703                24.25               4              17   \n",
       "494              690                28.66              34              20   \n",
       "495              675                41.75               9              12   \n",
       "496              709                57.83              10              17   \n",
       "\n",
       "     freq_cliche_words  freq_argument_words  freq_absolute_words  \\\n",
       "0                    0                    4                    3   \n",
       "1                    0                    3                    1   \n",
       "2                    0                    1                    0   \n",
       "3                    0                    5                    8   \n",
       "4                    0                    6                    3   \n",
       "5                    0                    5                    3   \n",
       "6                    0                    3                    0   \n",
       "7                    0                    9                    6   \n",
       "8                    0                    3                    0   \n",
       "9                    0                    2                    2   \n",
       "10                   0                    4                    4   \n",
       "11                   0                    2                    0   \n",
       "12                   1                    9                    2   \n",
       "13                   0                    9                    1   \n",
       "14                   0                   11                    1   \n",
       "15                   0                    9                    3   \n",
       "16                   0                    2                    2   \n",
       "17                   0                    9                    6   \n",
       "18                   0                    8                    3   \n",
       "19                   0                    7                    1   \n",
       "20                   0                    5                    2   \n",
       "21                   0                    8                    3   \n",
       "22                   0                   14                    4   \n",
       "23                   3                    3                    0   \n",
       "24                   0                    4                    8   \n",
       "25                   0                    4                    1   \n",
       "26                   0                   11                    1   \n",
       "27                   0                    7                    0   \n",
       "28                   0                    7                    4   \n",
       "29                   0                   10                    1   \n",
       "..                 ...                  ...                  ...   \n",
       "467                  0                    2                    6   \n",
       "468                  0                    9                    0   \n",
       "469                  0                   11                    0   \n",
       "470                  0                   10                    2   \n",
       "471                  0                    5                    3   \n",
       "472                  0                    4                    1   \n",
       "473                  0                    3                    2   \n",
       "474                  2                    6                    4   \n",
       "475                  0                   15                    0   \n",
       "476                  1                    6                    0   \n",
       "477                  0                    5                    2   \n",
       "478                  0                    8                    0   \n",
       "479                  0                    8                    0   \n",
       "480                  0                    7                    5   \n",
       "481                  0                    6                    0   \n",
       "482                  0                    7                    5   \n",
       "483                  0                   11                    0   \n",
       "484                  0                    8                    4   \n",
       "485                  0                    6                    2   \n",
       "486                  0                    9                    0   \n",
       "487                  0                    6                    2   \n",
       "488                  0                    7                    0   \n",
       "489                  0                   11                    1   \n",
       "490                  0                   14                    1   \n",
       "491                  0                    5                    0   \n",
       "492                  0                   12                    2   \n",
       "493                  1                    6                    5   \n",
       "494                  0                    7                    4   \n",
       "495                  0                   12                    2   \n",
       "496                  0                    5                    2   \n",
       "\n",
       "     complex_part_speech  vari_part_speech  \n",
       "0              16.602151                25  \n",
       "1              28.927273                33  \n",
       "2              32.184211                22  \n",
       "3              28.017544                30  \n",
       "4              22.727273                31  \n",
       "5              23.707692                28  \n",
       "6              24.403226                28  \n",
       "7              21.338028                28  \n",
       "8              27.648148                33  \n",
       "9              20.520548                33  \n",
       "10             18.790123                29  \n",
       "11             21.600000                31  \n",
       "12             28.740741                30  \n",
       "13             20.945946                31  \n",
       "14             24.060606                34  \n",
       "15             18.375000                32  \n",
       "16             20.938462                26  \n",
       "17             20.714286                28  \n",
       "18             24.873016                30  \n",
       "19             20.929577                31  \n",
       "20             20.643836                33  \n",
       "21             20.796875                30  \n",
       "22             16.936842                32  \n",
       "23             27.947368                31  \n",
       "24             30.219512                28  \n",
       "25             17.719101                28  \n",
       "26             29.396552                31  \n",
       "27             25.103448                32  \n",
       "28             21.405405                34  \n",
       "29             17.600000                29  \n",
       "..                   ...               ...  \n",
       "467            23.220000                28  \n",
       "468            19.028986                26  \n",
       "469            20.623377                30  \n",
       "470            26.830508                30  \n",
       "471            22.471429                33  \n",
       "472            26.559322                30  \n",
       "473            22.545455                28  \n",
       "474            21.298507                35  \n",
       "475            27.637931                33  \n",
       "476            25.163934                32  \n",
       "477            24.730159                28  \n",
       "478            22.900000                33  \n",
       "479            27.021739                25  \n",
       "480            21.583333                29  \n",
       "481            24.423729                28  \n",
       "482            24.984375                33  \n",
       "483            22.890909                28  \n",
       "484            22.560606                31  \n",
       "485            21.500000                30  \n",
       "486            25.523810                34  \n",
       "487            26.163934                31  \n",
       "488            25.822581                32  \n",
       "489            18.406977                24  \n",
       "490            28.535714                31  \n",
       "491            21.888889                35  \n",
       "492            29.648148                31  \n",
       "493            23.246377                34  \n",
       "494            24.227273                33  \n",
       "495            18.928571                33  \n",
       "496            17.649351                28  \n",
       "\n",
       "[497 rows x 21 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_text_feature(df, col='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with features from text\n",
    "\n",
    "test_data = gen_text_feature(df, col='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>level</th>\n",
       "      <th>title_name</th>\n",
       "      <th>vocab_richness</th>\n",
       "      <th>mean_word_syllable</th>\n",
       "      <th>word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>freq_wok_words</th>\n",
       "      <th>freq_aok_words</th>\n",
       "      <th>freq_cliche_words</th>\n",
       "      <th>freq_argument_words</th>\n",
       "      <th>freq_absolute_words</th>\n",
       "      <th>complex_part_speech</th>\n",
       "      <th>vari_part_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the question is asking that in the same discip...</td>\n",
       "      <td>2017</td>\n",
       "      <td>4, 5 - Est_Chen-fzn235-TOK_essay.docx</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Given access to the same facts, how is it poss...</td>\n",
       "      <td>0.209360</td>\n",
       "      <td>1.540025</td>\n",
       "      <td>1525</td>\n",
       "      <td>...</td>\n",
       "      <td>16.223404</td>\n",
       "      <td>788</td>\n",
       "      <td>60.08</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>16.602151</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>our brains seek coherence structure and order ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>7, 6 - Eva GuoTOK_final_final_draft.docx</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Humans are pattern-seeking animals and we are ...</td>\n",
       "      <td>0.344933</td>\n",
       "      <td>1.731380</td>\n",
       "      <td>1575</td>\n",
       "      <td>...</td>\n",
       "      <td>27.155172</td>\n",
       "      <td>724</td>\n",
       "      <td>32.80</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28.927273</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  year  \\\n",
       "0  the question is asking that in the same discip...  2017   \n",
       "1  our brains seek coherence structure and order ...  2017   \n",
       "\n",
       "                                       name  title  score  level  \\\n",
       "0     4, 5 - Est_Chen-fzn235-TOK_essay.docx      5      4      2   \n",
       "1  7, 6 - Eva GuoTOK_final_final_draft.docx      6      7      4   \n",
       "\n",
       "                                          title_name  vocab_richness  \\\n",
       "0  Given access to the same facts, how is it poss...        0.209360   \n",
       "1  Humans are pattern-seeking animals and we are ...        0.344933   \n",
       "\n",
       "   mean_word_syllable  word_count  ...  avg_sentence_length  count_stopwords  \\\n",
       "0            1.540025        1525  ...            16.223404              788   \n",
       "1            1.731380        1575  ...            27.155172              724   \n",
       "\n",
       "   flesch_reading_ease  freq_wok_words  freq_aok_words  freq_cliche_words  \\\n",
       "0                60.08              25              52                  0   \n",
       "1                32.80              11               7                  0   \n",
       "\n",
       "   freq_argument_words  freq_absolute_words  complex_part_speech  \\\n",
       "0                    4                    3            16.602151   \n",
       "1                    3                    1            28.927273   \n",
       "\n",
       "   vari_part_speech  \n",
       "0                25  \n",
       "1                33  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with features from title\n",
    "\n",
    "from essay_grader.title_text_similarity import gen_title_text_similarity_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-26 11:49:41 WARNING: Can not find mwt: default from official model list. Ignoring it.\n",
      "2020-08-26 11:49:41 INFO: Loading these models for language: en (English):\n",
      "=======================\n",
      "| Processor | Package |\n",
      "-----------------------\n",
      "| tokenize  | ewt     |\n",
      "| pos       | ewt     |\n",
      "| lemma     | ewt     |\n",
      "=======================\n",
      "\n",
      "2020-08-26 11:49:41 INFO: Use device: cpu\n",
      "2020-08-26 11:49:41 INFO: Loading: tokenize\n",
      "2020-08-26 11:49:41 INFO: Loading: pos\n",
      "2020-08-26 11:49:42 INFO: Loading: lemma\n",
      "2020-08-26 11:49:42 INFO: Done loading processors!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>level</th>\n",
       "      <th>title_name</th>\n",
       "      <th>title_key_word</th>\n",
       "      <th>frequency_title_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the question is asking that in the same discip...</td>\n",
       "      <td>2017</td>\n",
       "      <td>4, 5 - Est_Chen-fzn235-TOK_essay.docx</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>given access to the same facts  how is it poss...</td>\n",
       "      <td>[(give, v), (access, n), (fact, n), (disagreem...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in american heritage dictionary of the english...</td>\n",
       "      <td>2017</td>\n",
       "      <td>7, 5 - fzn260_Yessica_Ji_Yuanyi_G12-9_TOKEssay...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>given access to the same facts  how is it poss...</td>\n",
       "      <td>[(give, v), (access, n), (fact, n), (disagreem...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  year  \\\n",
       "0  the question is asking that in the same discip...  2017   \n",
       "1  in american heritage dictionary of the english...  2017   \n",
       "\n",
       "                                                name  title  score  level  \\\n",
       "0              4, 5 - Est_Chen-fzn235-TOK_essay.docx      5      4      2   \n",
       "1  7, 5 - fzn260_Yessica_Ji_Yuanyi_G12-9_TOKEssay...      5      7      4   \n",
       "\n",
       "                                          title_name  \\\n",
       "0  given access to the same facts  how is it poss...   \n",
       "1  given access to the same facts  how is it poss...   \n",
       "\n",
       "                                      title_key_word  frequency_title_words  \n",
       "0  [(give, v), (access, n), (fact, n), (disagreem...                     89  \n",
       "1  [(give, v), (access, n), (fact, n), (disagreem...                     72  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_features = gen_title_text_similarity_features(df, col_text = 'text', col_titles = 'title_name')\n",
    "title_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>level</th>\n",
       "      <th>title_name</th>\n",
       "      <th>vocab_richness</th>\n",
       "      <th>mean_word_syllable</th>\n",
       "      <th>word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>freq_wok_words</th>\n",
       "      <th>freq_aok_words</th>\n",
       "      <th>freq_cliche_words</th>\n",
       "      <th>freq_argument_words</th>\n",
       "      <th>freq_absolute_words</th>\n",
       "      <th>complex_part_speech</th>\n",
       "      <th>vari_part_speech</th>\n",
       "      <th>frequency_title_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the question is asking that in the same discip...</td>\n",
       "      <td>2017</td>\n",
       "      <td>4, 5 - Est_Chen-fzn235-TOK_essay.docx</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Given access to the same facts, how is it poss...</td>\n",
       "      <td>0.20936</td>\n",
       "      <td>1.540025</td>\n",
       "      <td>1525</td>\n",
       "      <td>...</td>\n",
       "      <td>788</td>\n",
       "      <td>60.08</td>\n",
       "      <td>25</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>16.602151</td>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  year  \\\n",
       "0  the question is asking that in the same discip...  2017   \n",
       "\n",
       "                                    name  title  score  level  \\\n",
       "0  4, 5 - Est_Chen-fzn235-TOK_essay.docx      5      4      2   \n",
       "\n",
       "                                          title_name  vocab_richness  \\\n",
       "0  Given access to the same facts, how is it poss...         0.20936   \n",
       "\n",
       "   mean_word_syllable  word_count  ...  count_stopwords  flesch_reading_ease  \\\n",
       "0            1.540025        1525  ...              788                60.08   \n",
       "\n",
       "   freq_wok_words  freq_aok_words  freq_cliche_words  freq_argument_words  \\\n",
       "0              25              52                  0                    4   \n",
       "\n",
       "   freq_absolute_words  complex_part_speech  vari_part_speech  \\\n",
       "0                    3            16.602151                25   \n",
       "\n",
       "   frequency_title_words  \n",
       "0                     89  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data2 = pd.concat([test_data,title_features['frequency_title_words']],axis=1)\n",
    "test_data2.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vocab_richness', 'mean_word_syllable', 'word_count', 'sentence_count',\n",
       "       'count_stopwords', 'flesch_reading_ease', 'freq_wok_words',\n",
       "       'freq_aok_words', 'freq_cliche_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pca features\n",
    "X_test = pd.concat([test_data2.iloc[:,7:11],test_data2.iloc[:,12:17]], axis=1)\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vocab_richness', 'mean_word_syllable', 'word_count', 'sentence_count',\n",
       "       'avg_sentence_length', 'count_stopwords', 'flesch_reading_ease',\n",
       "       'freq_wok_words', 'freq_aok_words', 'freq_cliche_words',\n",
       "       'freq_argument_words', 'freq_absolute_words', 'complex_part_speech',\n",
       "       'vari_part_speech', 'frequency_title_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all features\n",
    "X_test = test_data2.iloc[:,7:]\n",
    "X_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vocab_richness', 'mean_word_syllable', 'word_count', 'sentence_count',\n",
       "       'avg_sentence_length', 'count_stopwords', 'flesch_reading_ease',\n",
       "       'freq_wok_words', 'freq_aok_words', 'freq_cliche_words',\n",
       "       'freq_argument_words', 'freq_absolute_words', 'complex_part_speech',\n",
       "       'vari_part_speech', 'frequency_title_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data2.iloc[:,7:].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# nomalized the data\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalizer = MinMaxScaler()\n",
    "\n",
    "normalizer.fit(test_data2.iloc[:,7:])\n",
    "\n",
    "test_data2.iloc[:,7:] = normalizer.transform(test_data2.iloc[:,7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>level</th>\n",
       "      <th>title_name</th>\n",
       "      <th>vocab_richness</th>\n",
       "      <th>mean_word_syllable</th>\n",
       "      <th>word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>freq_wok_words</th>\n",
       "      <th>freq_aok_words</th>\n",
       "      <th>freq_cliche_words</th>\n",
       "      <th>freq_argument_words</th>\n",
       "      <th>freq_absolute_words</th>\n",
       "      <th>complex_part_speech</th>\n",
       "      <th>vari_part_speech</th>\n",
       "      <th>frequency_title_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the question is asking that in the same discip...</td>\n",
       "      <td>2017</td>\n",
       "      <td>4, 5 - Est_Chen-fzn235-TOK_essay.docx</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Given access to the same facts, how is it poss...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.221303</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792035</td>\n",
       "      <td>0.826360</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.090288</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.334586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>our brains seek coherence structure and order ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>7, 6 - Eva GuoTOK_final_final_draft.docx</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Humans are pattern-seeking animals and we are ...</td>\n",
       "      <td>0.672765</td>\n",
       "      <td>0.547228</td>\n",
       "      <td>0.757075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>0.387351</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.479306</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.270677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  year  \\\n",
       "0  the question is asking that in the same discip...  2017   \n",
       "1  our brains seek coherence structure and order ...  2017   \n",
       "\n",
       "                                       name  title  score  level  \\\n",
       "0     4, 5 - Est_Chen-fzn235-TOK_essay.docx      5      4      2   \n",
       "1  7, 6 - Eva GuoTOK_final_final_draft.docx      6      7      4   \n",
       "\n",
       "                                          title_name  vocab_richness  \\\n",
       "0  Given access to the same facts, how is it poss...        0.000000   \n",
       "1  Humans are pattern-seeking animals and we are ...        0.672765   \n",
       "\n",
       "   mean_word_syllable  word_count  ...  count_stopwords  flesch_reading_ease  \\\n",
       "0            0.221303    0.698113  ...         0.792035             0.826360   \n",
       "1            0.547228    0.757075  ...         0.650442             0.387351   \n",
       "\n",
       "   freq_wok_words  freq_aok_words  freq_cliche_words  freq_argument_words  \\\n",
       "0        0.403226        0.632911                0.0             0.210526   \n",
       "1        0.177419        0.063291                0.0             0.157895   \n",
       "\n",
       "   freq_absolute_words  complex_part_speech  vari_part_speech  \\\n",
       "0             0.230769             0.090288          0.217391   \n",
       "1             0.076923             0.479306          0.565217   \n",
       "\n",
       "   frequency_title_words  \n",
       "0               0.334586  \n",
       "1               0.270677  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X = test_data['complex_part_speech'] \n",
    "y = test_data2['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_y = pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split into Train/Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_test,y, test_size=0.3,random_state = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(layers.Dense(64, input_shape = (347,4), activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='tanh'))\n",
    "    model.add(layers.Dense(9, activation='softmax'))\n",
    "    \n",
    "        \n",
    "    opt = RMSprop(lr=0.005)\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                 optimizer=opt,\n",
    "                 metrics=['acc'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_65\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_114 (Dense)            (None, 347, 64)           320       \n",
      "_________________________________________________________________\n",
      "dense_115 (Dense)            (None, 347, 64)           4160      \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 347, 9)            585       \n",
      "=================================================================\n",
      "Total params: 5,065\n",
      "Trainable params: 5,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_cnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 347, 4) for input Tensor(\"dense_114_input:0\", shape=(None, 347, 4), dtype=float32), but it was called on an input with incompatible shape (None, 4).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 347, 4) for input Tensor(\"dense_114_input:0\", shape=(None, 347, 4), dtype=float32), but it was called on an input with incompatible shape (None, 4).\n",
      "62/93 [===================>..........] - ETA: 0s - loss: 2.0039 - acc: 0.1667    WARNING:tensorflow:Model was constructed with shape (None, 347, 4) for input Tensor(\"dense_114_input:0\", shape=(None, 347, 4), dtype=float32), but it was called on an input with incompatible shape (None, 4).\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 2.0027 - acc: 0.1986 - val_loss: 1.9418 - val_acc: 0.1714\n",
      "Epoch 2/10000\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.9576 - acc: 0.1949 - val_loss: 1.9102 - val_acc: 0.3000\n",
      "Epoch 3/10000\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.9360 - acc: 0.2202 - val_loss: 1.9281 - val_acc: 0.3286\n",
      "Epoch 4/10000\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.9266 - acc: 0.2274 - val_loss: 1.9012 - val_acc: 0.2714\n",
      "Epoch 5/10000\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.9202 - acc: 0.2166 - val_loss: 1.8816 - val_acc: 0.3143\n",
      "Epoch 6/10000\n",
      "93/93 [==============================] - 0s 926us/step - loss: 1.9081 - acc: 0.2491 - val_loss: 1.8853 - val_acc: 0.2714\n",
      "Epoch 7/10000\n",
      "93/93 [==============================] - 0s 921us/step - loss: 1.8961 - acc: 0.2022 - val_loss: 1.8790 - val_acc: 0.2714\n",
      "Epoch 8/10000\n",
      "93/93 [==============================] - 0s 948us/step - loss: 1.8816 - acc: 0.2419 - val_loss: 1.9514 - val_acc: 0.2143\n",
      "Epoch 9/10000\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.9050 - acc: 0.2166 - val_loss: 1.8716 - val_acc: 0.3143\n",
      "Epoch 10/10000\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.8809 - acc: 0.2455 - val_loss: 1.8746 - val_acc: 0.2857\n",
      "Epoch 11/10000\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.8897 - acc: 0.2527 - val_loss: 2.1360 - val_acc: 0.1429\n",
      "Epoch 12/10000\n",
      "93/93 [==============================] - 0s 932us/step - loss: 1.8796 - acc: 0.2347 - val_loss: 1.8852 - val_acc: 0.3143\n",
      "Epoch 13/10000\n",
      "93/93 [==============================] - 0s 900us/step - loss: 1.8841 - acc: 0.2094 - val_loss: 1.9525 - val_acc: 0.2429\n",
      "Epoch 14/10000\n",
      "93/93 [==============================] - 0s 954us/step - loss: 1.8765 - acc: 0.2202 - val_loss: 1.9098 - val_acc: 0.2286\n",
      "Epoch 15/10000\n",
      "93/93 [==============================] - 0s 932us/step - loss: 1.8642 - acc: 0.2383 - val_loss: 1.8916 - val_acc: 0.2143\n",
      "Epoch 16/10000\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.8740 - acc: 0.2383 - val_loss: 1.9120 - val_acc: 0.2429\n",
      "Epoch 17/10000\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.8732 - acc: 0.2274 - val_loss: 2.0908 - val_acc: 0.1857\n",
      "Epoch 18/10000\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.8858 - acc: 0.2455 - val_loss: 1.9966 - val_acc: 0.2429\n",
      "Epoch 19/10000\n",
      "93/93 [==============================] - 0s 1ms/step - loss: 1.8737 - acc: 0.2310 - val_loss: 1.9717 - val_acc: 0.2714\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    batch_size=3, \n",
    "                    epochs=10000,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-583-31d4077abeb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 81\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "y_pred = (model.predict(X_test)).round(0)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08336134453781513"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=10, random_state=2)\n",
    "\n",
    "cv_results = cross_validate(clf, \n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            scoring = \"accuracy\",\n",
    "                            cv=10)\n",
    "\n",
    "cv_results['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         3\n",
      "           1       0.00      0.00      0.00        13\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        41\n",
      "           4       0.00      0.00      0.00        23\n",
      "           5       0.00      0.00      0.00        15\n",
      "           6       0.00      0.00      0.00        15\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.00      0.00      0.00       150\n",
      "   macro avg       0.00      0.00      0.00       150\n",
      "weighted avg       0.00      0.00      0.00       150\n",
      " samples avg       0.00      0.00      0.00       150\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "y_pred = (model.predict(X_test)).round(0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2052: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/model_selection/_search.py:842: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "          estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "          fit_params=None, iid='warn', n_iter=200, n_jobs=None,\n",
       "          param_distributions={'n_neighbors': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1acb7e590>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Instanciate model\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Hyperparameter space\n",
    "param_distribution = {'n_neighbors': randint(1,100)}\n",
    "\n",
    "# Instanciate Grid Search\n",
    "random_search = RandomizedSearchCV(model, param_distribution, n_iter = 200)\n",
    "\n",
    "# Fit data to Grid Search\n",
    "random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25936599423631124"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import fasttext\n",
    "\n",
    "\n",
    "# changed to FastText required format\n",
    "train_df = df.iloc[:-50]\n",
    "train_df['label_level'] = '__label__' + train_df['level'].astype(str)\n",
    "train_df[['text','label_level']].to_csv('train.csv', index=None, header=None, sep='\\t')\n",
    "\n",
    "\n",
    "model = fasttext.train_supervised('train.csv', lr=1, wordNgrams=3, \n",
    "                                  verbose=2, minCount=1, epoch=25, loss=\"hs\",dim=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized the sentences\n",
    "sentences = []\n",
    "\n",
    "for i in test_data.index: \n",
    "\n",
    "    sentences.append(test_data['text'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_essay = []\n",
    "\n",
    "for index in range(len(sentences)):\n",
    "    length_essay.append(len(sentences[index]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(length_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized the tokens\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "vocab_size = 100000\n",
    "word_tokenizer = Tokenizer(num_words=vocab_size)\n",
    "\n",
    "word_tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "encode_sequences = word_tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19213"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_li2 = []\n",
    "for elt in encode_sequences:  \n",
    "    test_li2.append(max(elt))\n",
    "max(test_li2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size 19214\n"
     ]
    }
   ],
   "source": [
    "vocab_size = max([max(elt) for elt in encode_sequences]) + 1\n",
    "print('vocabulary size', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 1755\n"
     ]
    }
   ],
   "source": [
    "maxlen = max([len(elt) for elt in encode_sequences])\n",
    "print('Max length:', maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_encoder = np.zeros((len(encode_sequences), maxlen), dtype=np.float32)\n",
    "\n",
    "\n",
    "for i, sent in enumerate(encode_sequences):\n",
    "    for j, word_index in enumerate(sent):\n",
    "        input_encoder[i, j] = word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_55\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          1229696   \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, None, 64)          4160      \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, None, 5)           325       \n",
      "=================================================================\n",
      "Total params: 1,234,181\n",
      "Trainable params: 1,234,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=19214, output_dim=64))\n",
    "decoder_lstm = LSTM(64, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(embedded_decoder_inputs, initial_state=encoder_states)\n",
    "model.add(layers.Dense(64, activation='tanh'))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "opt = RMSprop(lr=0.005)\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "             optimizer=opt,\n",
    "             metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 5) and (None, 1755, 5) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-412-015cd6ea554c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     callbacks=[es])\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3142\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 5) and (None, 1755, 5) are incompatible\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    batch_size=3, \n",
    "                    epochs=10000,\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vocab_richness', 'mean_word_syllable', 'word_count', 'sentence_count',\n",
       "       'avg_sentence_length', 'count_stopwords', 'flesch_reading_ease',\n",
       "       'freq_wok_words', 'freq_aok_words', 'freq_cliche_words',\n",
       "       'freq_argument_words', 'freq_absolute_words', 'complex_part_speech',\n",
       "       'vari_part_speech', 'frequency_title_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['vocab_richness', 'mean_word_syllable', 'word_count', 'sentence_count',\n",
    "       'avg_sentence_length', 'count_stopwords', 'flesch_reading_ease',\n",
    "       'freq_wok_words', 'freq_aok_words', 'freq_cliche_words',\n",
    "       'freq_argument_words', 'freq_absolute_words', 'complex_part_speech',\n",
    "       'vari_part_speech', 'frequency_title_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "# define model\n",
    "# model = XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)\n",
    "# max_depth=10, n_estimators=300\n",
    "# max_depth=4, n_estimators=150\n",
    "model = RandomForestClassifier(max_depth=6, n_estimators=500)\n",
    "\n",
    "# define transform\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('scaler', MinMaxScaler())])\n",
    "\n",
    "text_transformer = Pipeline(steps=[\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                     ngram_range=(1,3), max_features=300\n",
    "            )),\n",
    "#             ('w2v', Vectorizer(\n",
    "#             )),    \n",
    "        ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "#         ('text', text_transformer, text_features),\n",
    "    ], remainder='drop')\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.24666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00        13\n",
      "           3       0.46      0.19      0.27        32\n",
      "           4       0.29      0.54      0.38        41\n",
      "           5       0.17      0.39      0.23        23\n",
      "           6       0.00      0.00      0.00        15\n",
      "           7       0.00      0.00      0.00        15\n",
      "           8       0.00      0.00      0.00         7\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.25      0.25      0.25       150\n",
      "   macro avg       0.10      0.12      0.10       150\n",
      "weighted avg       0.20      0.25      0.20       150\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# all features\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.29333333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00        13\n",
      "           3       0.64      0.22      0.33        32\n",
      "           4       0.33      0.51      0.40        41\n",
      "           5       0.21      0.52      0.30        23\n",
      "           6       0.22      0.27      0.24        15\n",
      "           7       0.00      0.00      0.00        15\n",
      "           8       0.00      0.00      0.00         7\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.29      0.29      0.29       150\n",
      "   macro avg       0.16      0.17      0.14       150\n",
      "weighted avg       0.28      0.29      0.25       150\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megan/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# selected features by PCA\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_score(y_test, preds):\n",
    "    total = len(y_test)\n",
    "    hits = 0 \n",
    "    for i,v in enumerate(preds):\n",
    "        if y_test.iloc[i]-v <2 and y_test.iloc[i]-v >-2:\n",
    "            hits +=1\n",
    "    return hits/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6266666666666667"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'year', 'name', 'title', 'score', 'level', 'title_name',\n",
       "       'vocab_richness', 'mean_word_syllable', 'word_count', 'sentence_count',\n",
       "       'avg_sentence_length', 'count_stopwords', 'flesch_reading_ease',\n",
       "       'freq_wok_words', 'freq_aok_words', 'freq_cliche_words',\n",
       "       'freq_argument_words', 'freq_absolute_words', 'complex_part_speech',\n",
       "       'vari_part_speech'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features from the body of the essay only\n",
    "test_df = test_data2.iloc[:,7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(test_df.corr(), cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "\n",
    "# find all Principal Components PC (no y!)\n",
    "pca.fit(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.354065</td>\n",
       "      <td>0.397704</td>\n",
       "      <td>-0.016363</td>\n",
       "      <td>-0.403256</td>\n",
       "      <td>0.375224</td>\n",
       "      <td>-0.169193</td>\n",
       "      <td>-0.489225</td>\n",
       "      <td>3.712116e-02</td>\n",
       "      <td>4.232215e-02</td>\n",
       "      <td>-0.011093</td>\n",
       "      <td>-0.076359</td>\n",
       "      <td>-0.096909</td>\n",
       "      <td>0.348796</td>\n",
       "      <td>0.026426</td>\n",
       "      <td>0.062891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.495049</td>\n",
       "      <td>0.115573</td>\n",
       "      <td>-0.337163</td>\n",
       "      <td>0.162377</td>\n",
       "      <td>-0.309458</td>\n",
       "      <td>-0.412406</td>\n",
       "      <td>0.048939</td>\n",
       "      <td>-8.385710e-02</td>\n",
       "      <td>-3.415180e-01</td>\n",
       "      <td>0.024401</td>\n",
       "      <td>-0.184863</td>\n",
       "      <td>-0.049179</td>\n",
       "      <td>-0.272218</td>\n",
       "      <td>-0.269913</td>\n",
       "      <td>0.159612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.110140</td>\n",
       "      <td>-0.139946</td>\n",
       "      <td>-0.176000</td>\n",
       "      <td>-0.220875</td>\n",
       "      <td>0.127288</td>\n",
       "      <td>-0.050855</td>\n",
       "      <td>0.053739</td>\n",
       "      <td>-2.039694e-01</td>\n",
       "      <td>-5.031755e-01</td>\n",
       "      <td>-0.030270</td>\n",
       "      <td>-0.022189</td>\n",
       "      <td>-0.090672</td>\n",
       "      <td>0.110729</td>\n",
       "      <td>-0.053583</td>\n",
       "      <td>-0.739794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.172703</td>\n",
       "      <td>-0.410954</td>\n",
       "      <td>-0.273080</td>\n",
       "      <td>-0.377379</td>\n",
       "      <td>0.232723</td>\n",
       "      <td>-0.029967</td>\n",
       "      <td>0.222210</td>\n",
       "      <td>-1.655205e-02</td>\n",
       "      <td>-1.100059e-01</td>\n",
       "      <td>0.074248</td>\n",
       "      <td>-0.348514</td>\n",
       "      <td>0.293063</td>\n",
       "      <td>0.198970</td>\n",
       "      <td>-0.168134</td>\n",
       "      <td>0.432173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.082604</td>\n",
       "      <td>0.018368</td>\n",
       "      <td>-0.273265</td>\n",
       "      <td>-0.054204</td>\n",
       "      <td>-0.081766</td>\n",
       "      <td>-0.290851</td>\n",
       "      <td>0.022670</td>\n",
       "      <td>5.569630e-02</td>\n",
       "      <td>7.119847e-01</td>\n",
       "      <td>-0.042218</td>\n",
       "      <td>-0.299100</td>\n",
       "      <td>0.123929</td>\n",
       "      <td>-0.070923</td>\n",
       "      <td>-0.198979</td>\n",
       "      <td>-0.402722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.157948</td>\n",
       "      <td>0.114311</td>\n",
       "      <td>0.073803</td>\n",
       "      <td>0.056186</td>\n",
       "      <td>-0.004567</td>\n",
       "      <td>-0.017442</td>\n",
       "      <td>-0.089263</td>\n",
       "      <td>-2.149743e-01</td>\n",
       "      <td>-5.283865e-02</td>\n",
       "      <td>-0.039194</td>\n",
       "      <td>0.239132</td>\n",
       "      <td>0.907870</td>\n",
       "      <td>-0.001083</td>\n",
       "      <td>0.033058</td>\n",
       "      <td>-0.109730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.231924</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.289474</td>\n",
       "      <td>0.179884</td>\n",
       "      <td>-0.018518</td>\n",
       "      <td>0.276184</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>8.452246e-02</td>\n",
       "      <td>-9.634246e-02</td>\n",
       "      <td>0.019939</td>\n",
       "      <td>-0.781909</td>\n",
       "      <td>0.121115</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.295425</td>\n",
       "      <td>-0.152290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.479786</td>\n",
       "      <td>0.299853</td>\n",
       "      <td>0.027701</td>\n",
       "      <td>0.090528</td>\n",
       "      <td>-0.044730</td>\n",
       "      <td>-0.141306</td>\n",
       "      <td>-0.219243</td>\n",
       "      <td>6.366516e-01</td>\n",
       "      <td>-3.021054e-01</td>\n",
       "      <td>0.066203</td>\n",
       "      <td>-0.103592</td>\n",
       "      <td>0.182882</td>\n",
       "      <td>-0.057343</td>\n",
       "      <td>-0.228403</td>\n",
       "      <td>-0.016929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.483695</td>\n",
       "      <td>-0.321331</td>\n",
       "      <td>-0.047055</td>\n",
       "      <td>-0.092783</td>\n",
       "      <td>0.058310</td>\n",
       "      <td>0.018457</td>\n",
       "      <td>0.230216</td>\n",
       "      <td>6.847251e-01</td>\n",
       "      <td>3.174354e-02</td>\n",
       "      <td>0.094709</td>\n",
       "      <td>0.260679</td>\n",
       "      <td>0.063819</td>\n",
       "      <td>0.060062</td>\n",
       "      <td>0.100626</td>\n",
       "      <td>-0.175034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.189285</td>\n",
       "      <td>0.062439</td>\n",
       "      <td>-0.336221</td>\n",
       "      <td>-0.084783</td>\n",
       "      <td>-0.118096</td>\n",
       "      <td>-0.325611</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>3.703880e-02</td>\n",
       "      <td>-4.518795e-02</td>\n",
       "      <td>0.037909</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>0.034150</td>\n",
       "      <td>-0.079513</td>\n",
       "      <td>0.838631</td>\n",
       "      <td>0.065923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.008507</td>\n",
       "      <td>0.037531</td>\n",
       "      <td>0.038007</td>\n",
       "      <td>0.016498</td>\n",
       "      <td>-0.003742</td>\n",
       "      <td>-0.004829</td>\n",
       "      <td>-0.028288</td>\n",
       "      <td>-1.213657e-01</td>\n",
       "      <td>5.060343e-02</td>\n",
       "      <td>0.986847</td>\n",
       "      <td>0.022888</td>\n",
       "      <td>-0.006110</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>-0.021467</td>\n",
       "      <td>-0.061453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.042025</td>\n",
       "      <td>-0.244062</td>\n",
       "      <td>0.537953</td>\n",
       "      <td>0.230888</td>\n",
       "      <td>0.197886</td>\n",
       "      <td>-0.708778</td>\n",
       "      <td>0.104719</td>\n",
       "      <td>-5.444221e-02</td>\n",
       "      <td>-1.623645e-02</td>\n",
       "      <td>-0.020764</td>\n",
       "      <td>-0.019914</td>\n",
       "      <td>-0.031773</td>\n",
       "      <td>0.194692</td>\n",
       "      <td>0.021909</td>\n",
       "      <td>0.004836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.007708</td>\n",
       "      <td>0.010776</td>\n",
       "      <td>-0.397477</td>\n",
       "      <td>0.611465</td>\n",
       "      <td>0.019629</td>\n",
       "      <td>0.082806</td>\n",
       "      <td>-0.017657</td>\n",
       "      <td>2.717403e-03</td>\n",
       "      <td>7.698318e-03</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>-0.007943</td>\n",
       "      <td>0.678170</td>\n",
       "      <td>-0.000711</td>\n",
       "      <td>0.003419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.012880</td>\n",
       "      <td>0.150066</td>\n",
       "      <td>0.227458</td>\n",
       "      <td>-0.360418</td>\n",
       "      <td>-0.717127</td>\n",
       "      <td>-0.032526</td>\n",
       "      <td>0.207469</td>\n",
       "      <td>2.420434e-03</td>\n",
       "      <td>-9.516098e-03</td>\n",
       "      <td>-0.006552</td>\n",
       "      <td>-0.003249</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.486117</td>\n",
       "      <td>-0.028463</td>\n",
       "      <td>0.001238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.588076</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.335938</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.735739</td>\n",
       "      <td>-6.316744e-07</td>\n",
       "      <td>-7.753215e-07</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.354065  0.397704 -0.016363 -0.403256  0.375224 -0.169193 -0.489225   \n",
       "1   0.495049  0.115573 -0.337163  0.162377 -0.309458 -0.412406  0.048939   \n",
       "2  -0.110140 -0.139946 -0.176000 -0.220875  0.127288 -0.050855  0.053739   \n",
       "3  -0.172703 -0.410954 -0.273080 -0.377379  0.232723 -0.029967  0.222210   \n",
       "4  -0.082604  0.018368 -0.273265 -0.054204 -0.081766 -0.290851  0.022670   \n",
       "5   0.157948  0.114311  0.073803  0.056186 -0.004567 -0.017442 -0.089263   \n",
       "6   0.231924  0.009666  0.289474  0.179884 -0.018518  0.276184  0.000752   \n",
       "7  -0.479786  0.299853  0.027701  0.090528 -0.044730 -0.141306 -0.219243   \n",
       "8   0.483695 -0.321331 -0.047055 -0.092783  0.058310  0.018457  0.230216   \n",
       "9  -0.189285  0.062439 -0.336221 -0.084783 -0.118096 -0.325611  0.004013   \n",
       "10 -0.008507  0.037531  0.038007  0.016498 -0.003742 -0.004829 -0.028288   \n",
       "11 -0.042025 -0.244062  0.537953  0.230888  0.197886 -0.708778  0.104719   \n",
       "12 -0.007708  0.010776 -0.397477  0.611465  0.019629  0.082806 -0.017657   \n",
       "13 -0.012880  0.150066  0.227458 -0.360418 -0.717127 -0.032526  0.207469   \n",
       "14 -0.000008  0.588076 -0.000018  0.000020  0.335938  0.000005  0.735739   \n",
       "\n",
       "              7             8         9         10        11        12  \\\n",
       "0   3.712116e-02  4.232215e-02 -0.011093 -0.076359 -0.096909  0.348796   \n",
       "1  -8.385710e-02 -3.415180e-01  0.024401 -0.184863 -0.049179 -0.272218   \n",
       "2  -2.039694e-01 -5.031755e-01 -0.030270 -0.022189 -0.090672  0.110729   \n",
       "3  -1.655205e-02 -1.100059e-01  0.074248 -0.348514  0.293063  0.198970   \n",
       "4   5.569630e-02  7.119847e-01 -0.042218 -0.299100  0.123929 -0.070923   \n",
       "5  -2.149743e-01 -5.283865e-02 -0.039194  0.239132  0.907870 -0.001083   \n",
       "6   8.452246e-02 -9.634246e-02  0.019939 -0.781909  0.121115  0.000929   \n",
       "7   6.366516e-01 -3.021054e-01  0.066203 -0.103592  0.182882 -0.057343   \n",
       "8   6.847251e-01  3.174354e-02  0.094709  0.260679  0.063819  0.060062   \n",
       "9   3.703880e-02 -4.518795e-02  0.037909  0.008188  0.034150 -0.079513   \n",
       "10 -1.213657e-01  5.060343e-02  0.986847  0.022888 -0.006110  0.002887   \n",
       "11 -5.444221e-02 -1.623645e-02 -0.020764 -0.019914 -0.031773  0.194692   \n",
       "12  2.717403e-03  7.698318e-03  0.002265  0.018178 -0.007943  0.678170   \n",
       "13  2.420434e-03 -9.516098e-03 -0.006552 -0.003249  0.005684  0.486117   \n",
       "14 -6.316744e-07 -7.753215e-07 -0.000001  0.000015 -0.000017  0.000058   \n",
       "\n",
       "          13        14  \n",
       "0   0.026426  0.062891  \n",
       "1  -0.269913  0.159612  \n",
       "2  -0.053583 -0.739794  \n",
       "3  -0.168134  0.432173  \n",
       "4  -0.198979 -0.402722  \n",
       "5   0.033058 -0.109730  \n",
       "6   0.295425 -0.152290  \n",
       "7  -0.228403 -0.016929  \n",
       "8   0.100626 -0.175034  \n",
       "9   0.838631  0.065923  \n",
       "10 -0.021467 -0.061453  \n",
       "11  0.021909  0.004836  \n",
       "12 -0.000711  0.003419  \n",
       "13 -0.028463  0.001238  \n",
       "14  0.000002  0.000010  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the PCs (as rows)\n",
    "# Expressed as linear combination of initial vector basis (13 columns)\n",
    "Wt = pd.DataFrame(pca.components_)\n",
    "Wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.495049\n",
       "8     0.483695\n",
       "7     0.479786\n",
       "0     0.354065\n",
       "6     0.231924\n",
       "9     0.189285\n",
       "3     0.172703\n",
       "5     0.157948\n",
       "2     0.110140\n",
       "4     0.082604\n",
       "11    0.042025\n",
       "13    0.012880\n",
       "10    0.008507\n",
       "12    0.007708\n",
       "14    0.000008\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(Wt[0]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.DataFrame(Wt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'year', 'name', 'title', 'score', 'level', 'title_name',\n",
       "       'vocab_richness', 'mean_word_syllable', 'word_count', 'sentence_count',\n",
       "       'avg_sentence_length', 'count_stopwords', 'flesch_reading_ease',\n",
       "       'freq_wok_words', 'freq_aok_words', 'freq_cliche_words',\n",
       "       'freq_argument_words', 'freq_absolute_words', 'complex_part_speech',\n",
       "       'vari_part_speech', 'frequency_title_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title_name</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vocab_richness</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_word_syllable</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_count</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_stopwords</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq_wok_words</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq_aok_words</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq_cliche_words</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq_argument_words</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq_absolute_words</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex_part_speech</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vari_part_speech</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency_title_words</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0\n",
       "text                  NaN\n",
       "year                  NaN\n",
       "name                  NaN\n",
       "title                 NaN\n",
       "score                 NaN\n",
       "level                 NaN\n",
       "title_name            NaN\n",
       "vocab_richness        NaN\n",
       "mean_word_syllable    NaN\n",
       "word_count            NaN\n",
       "sentence_count        NaN\n",
       "avg_sentence_length   NaN\n",
       "count_stopwords       NaN\n",
       "flesch_reading_ease   NaN\n",
       "freq_wok_words        NaN\n",
       "freq_aok_words        NaN\n",
       "freq_cliche_words     NaN\n",
       "freq_argument_words   NaN\n",
       "freq_absolute_words   NaN\n",
       "complex_part_speech   NaN\n",
       "vari_part_speech      NaN\n",
       "frequency_title_words NaN"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Wt[0],test_data2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp = pca.transform(test_df) # Dataset expressed/projected in the new PC basis.  (eq. X.dot(Wt.T))\n",
    "Rated_features = pd.DataFrame(Xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x18376d990>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(13,5))\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.title('X1 vs. X0 before PCA (initial basis)'); plt.xlabel('X0'); plt.ylabel('X1')\n",
    "# plt.scatter(test_df[:,0], test_df[:,1])\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Xp1 vs Xp0 after PCA (new basis)'); plt.xlabel('PC 1'); plt.ylabel('PC 2')\n",
    "plt.scatter(Xp[:,0], Xp[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23197, 0.14339, 0.11712, 0.10231, 0.0889 , 0.0817 , 0.06614,\n",
       "       0.05433, 0.04483, 0.03089, 0.02723, 0.00728, 0.00303, 0.00089,\n",
       "       0.     ])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pca.explained_variance_ratio_).round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>name</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>level</th>\n",
       "      <th>title_name</th>\n",
       "      <th>vocab_richness</th>\n",
       "      <th>mean_word_syllable</th>\n",
       "      <th>word_count</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>freq_wok_words</th>\n",
       "      <th>freq_aok_words</th>\n",
       "      <th>freq_cliche_words</th>\n",
       "      <th>freq_argument_words</th>\n",
       "      <th>freq_absolute_words</th>\n",
       "      <th>complex_part_speech</th>\n",
       "      <th>vari_part_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the question is asking that in the same discip...</td>\n",
       "      <td>2017</td>\n",
       "      <td>4, 5 - Est_Chen-fzn235-TOK_essay.docx</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Given access to the same facts, how is it poss...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.221303</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095829</td>\n",
       "      <td>0.792035</td>\n",
       "      <td>0.826360</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.090288</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>our brains seek coherence structure and order ...</td>\n",
       "      <td>2017</td>\n",
       "      <td>7, 6 - Eva GuoTOK_final_final_draft.docx</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>Humans are pattern-seeking animals and we are ...</td>\n",
       "      <td>0.672765</td>\n",
       "      <td>0.547228</td>\n",
       "      <td>0.757075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486870</td>\n",
       "      <td>0.650442</td>\n",
       "      <td>0.387351</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.479306</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  year  \\\n",
       "0  the question is asking that in the same discip...  2017   \n",
       "1  our brains seek coherence structure and order ...  2017   \n",
       "\n",
       "                                       name  title  score  level  \\\n",
       "0     4, 5 - Est_Chen-fzn235-TOK_essay.docx      5      4      2   \n",
       "1  7, 6 - Eva GuoTOK_final_final_draft.docx      6      7      4   \n",
       "\n",
       "                                          title_name  vocab_richness  \\\n",
       "0  Given access to the same facts, how is it poss...        0.000000   \n",
       "1  Humans are pattern-seeking animals and we are ...        0.672765   \n",
       "\n",
       "   mean_word_syllable  word_count  ...  avg_sentence_length  count_stopwords  \\\n",
       "0            0.221303    0.698113  ...             0.095829         0.792035   \n",
       "1            0.547228    0.757075  ...             0.486870         0.650442   \n",
       "\n",
       "   flesch_reading_ease  freq_wok_words  freq_aok_words  freq_cliche_words  \\\n",
       "0             0.826360        0.403226        0.632911                0.0   \n",
       "1             0.387351        0.177419        0.063291                0.0   \n",
       "\n",
       "   freq_argument_words  freq_absolute_words  complex_part_speech  \\\n",
       "0             0.235294             0.230769             0.090288   \n",
       "1             0.176471             0.076923             0.479306   \n",
       "\n",
       "   vari_part_speech  \n",
       "0          0.217391  \n",
       "1          0.565217  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = test_data.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...True,\n",
       "        vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'tfidf__ngram_range': ((1, 1), (2, 2)), 'nb__alpha': (0.1, 1)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "\n",
    "# Create Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('nb', MultinomialNB()),\n",
    "])\n",
    "\n",
    "# Set parameters to search\n",
    "parameters = {\n",
    "    'tfidf__ngram_range': ((1,1), (2,2)),\n",
    "    'nb__alpha': (0.1,1),}\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, \n",
    "                           verbose=1, scoring = \"accuracy\", \n",
    "                           refit=True, cv=5)\n",
    "\n",
    "grid_search.fit(test_data.text,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2595573440643863"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine features from title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
